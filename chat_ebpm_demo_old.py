# chat_ebpm_demo.py
from __future__ import annotations
import json, re, time, uuid, os
from datetime import datetime
from typing import List, Dict, Tuple, Any, Optional
from collections import Counter, defaultdict
import itertools
from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import requests
import graphviz
import numpy as np
try:
    import pulp
    HAS_PULP = True
except Exception:
    HAS_PULP = False
from dotenv import load_dotenv
# ==== è¿½åŠ  ====
from ebpm_agents_old.complex_orchestrator import (
    run_complex_pipeline, refine_problem, decompose_work, run_searches,
    synthesize_strategies, critique_strategies, estimate_budgets, explore_topics,
    build_policy_hypotheses
)
from ebpm_agents_old.dummy_data_agent import DummyDataAgent
from ebpm_agents_old.kpi_template_agent import KPITemplateAgent, DEFAULT_KPI_TEMPLATES
from ebpm_agents_old.hypothesis_gap_agent import HypothesisGapAgent
from ebpm_agents_old.agent_competition_manager import AgentCompetitionManager, DEFAULT_CONTESTANTS


# ==== Agents/Research orchestrators ====
_HAS_AGENTS = True
_AGENTS_IMPORT_ERR = ""
try:
    from ebpm_agents_old.orchestrator import run_pipeline as run_ebpm_agents
    from ebpm_agents_old.research_orchestrator import (
        build_rs_primer, extract_effect_pathway, seed_kpis_from_fragments,
        update_kpis_with_pdfs, build_kpi_timeseries, collect_edges, run_causality
    )
    from ebpm_agents_old.utils import extract_pdf_text, join_with_markers
except Exception as _e:
    _HAS_AGENTS = False
    _AGENTS_IMPORT_ERR = str(_e)

# .env
_ENV_PATHS = [
    Path(__file__).resolve().parent / ".env",
    Path.cwd() / "Better-EBPM" / ".env",
    Path.cwd() / ".env",
]
_ENV_LOADED_FROM = None
for p in _ENV_PATHS:
    try:
        if p.is_file() and load_dotenv(dotenv_path=p):
            _ENV_LOADED_FROM = str(p); break
    except Exception:
        pass
if _ENV_LOADED_FROM is None:
    load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY", "")

# ===== OpenAI SDK ä¸¡å¯¾å¿œï¼ˆv0.28ç³» / v1ç³»ï¼‰ =====
_HAS_OPENAI = False
_CLIENT_KIND = "none"
try:
    from openai import OpenAI  # v1.x
    _HAS_OPENAI = True; _CLIENT_KIND = "v1"
except Exception:
    try:
        import openai  # legacy
        _HAS_OPENAI = True; _CLIENT_KIND = "legacy"
    except Exception:
        _HAS_OPENAI = False

st.set_page_config(page_title="EBPM Chat Demo (Agents+Research)", layout="wide")

# --------------------
# ãƒ€ãƒŸãƒ¼çŸ¥è­˜ãƒ™ãƒ¼ã‚¹
# --------------------
KPI_CATALOG = {
    "åœ°åŸŸåŒ»ç™‚": ["æ•‘æ€¥å—å…¥ç‡(%)", "åŒ»å¸«1äººã‚ãŸã‚Šæ‚£è€…æ•°(äºº)", "åˆè¨ºå¾…æ©Ÿæ—¥æ•°(æ—¥)"],
    "å­è‚²ã¦": ["ä¿è‚²æ‰€å¾…æ©Ÿå…ç«¥æ•°(äºº)", "å‡ºç”Ÿç‡(%)", "æ¯å­ä¿å¥å—è¨ºç‡(%)"],
    "é›‡ç”¨": ["æœ‰åŠ¹æ±‚äººå€ç‡(å€)", "é›¢è·ç‡(%)", "å¹³å‡é€šå‹¤æ™‚é–“(åˆ†)"],
}
POLICY_LIBRARY = {
    "å¥¨å­¦é‡‘è¿”é‚„å…é™¤":   {"cost": 3.0, "effect": 12.0, "lag": 2, "risk": "ä¸­"},
    "ICTåŠ¹ç‡åŒ–":       {"cost": 2.0, "effect": 9.0,  "lag": 1, "risk": "ä½"},
    "åŒ»ç™‚ã‚¯ãƒ©ãƒ¼ã‚¯å¢—å“¡": {"cost": 1.5, "effect": 7.0,  "lag": 0, "risk": "ä¸­"},
    "çµ¦ä¸å¼•ä¸Šã’":       {"cost": 4.0, "effect": 14.0, "lag": 1, "risk": "é«˜"},
    "ãƒ‰ã‚¯ã‚¿ãƒ¼ãƒãƒ³ã‚¯":   {"cost": 2.5, "effect": 8.0,  "lag": 1, "risk": "ä¸­"},
}
RISK_NOTE = {"ä½": "å®Ÿè£…å®¹æ˜“", "ä¸­": "é‹ç”¨èª¿æ•´å¿…è¦", "é«˜": "æ”¿æ²»ãƒ»äººæãƒãƒ¼ãƒ‰ãƒ«"}

POLICY_STAGE_FLOW = [
    {"name": "å•é¡Œæ„è­˜", "desc": "èª²é¡Œã®èƒŒæ™¯ã¨ç—›ç‚¹ã‚’æ•´ç†"},
    {"name": "ä»®èª¬å½¢æˆ", "desc": "è³ªçš„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŸå› ã‚’æ´—ã„å‡ºã—"},
    {"name": "æ–½ç­–è¨­è¨ˆ", "desc": "æ–½ç­–å€™è£œã‚’åˆ—æŒ™ã—æ¯”è¼ƒ"},
    {"name": "æ¤œè¨¼ãƒ»ã‚·ãƒŸãƒ¥", "desc": "ã‚·ãƒŠãƒªã‚ªã‚„KPIãƒ¬ãƒ³ã‚¸ã‚’ç¢ºèª"},
    {"name": "æ„æ€æ±ºå®š", "desc": "ã‚³ãƒ¡ãƒ³ãƒˆè¨˜éŒ²ãƒ»é–¢ä¿‚è€…åˆæ„"},
]

STAGE_ACTION_HINTS = {
    "å•é¡Œæ„è­˜": ["èª²é¡Œã‚’ãƒãƒ£ãƒƒãƒˆã«å…¥åŠ›", "KPIãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆ"],
    "ä»®èª¬å½¢æˆ": ["è³ªçš„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ä»®èª¬ã®è£œå¼·ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª"],
    "æ–½ç­–è¨­è¨ˆ": ["æ–½ç­–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ", "Agentã‚³ãƒ³ãƒšã§æ¡ˆã‚’æ¯”è¼ƒ"],
    "æ¤œè¨¼ãƒ»ã‚·ãƒŸãƒ¥": ["ã‚·ãƒŠãƒªã‚ªæœ€é©åŒ–ã‚’å®Ÿè¡Œ", "KPIãƒ¬ãƒ³ã‚¸ã§é–¾å€¤é•åã‚’ãƒã‚§ãƒƒã‚¯"],
    "æ„æ€æ±ºå®š": ["æ”¿ç­–æ‹…å½“è€…ãƒ¡ãƒ¢ã«æ„æ€ã‚’è¨˜éŒ²", "é–¢ä¿‚è€…å‘ã‘ãƒ†ãƒ³ãƒ—ãƒ¬ã‚’ä½œæˆ"],
}

SPECIAL_ACTION_DEFS = [
    {
        "name": "simulate",
        "keywords": ["ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", "åŠ¹æœã‚’æ¤œè¨¼"],
        "message": "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯ Step 5 ã§ã‚·ãƒŠãƒªã‚ªè¨­å®šâ†’æœ€é©åŒ–â†’KPIãƒ¬ãƒ³ã‚¸ç¢ºèªã®é †ã«å®Ÿè¡Œã§ãã¾ã™ã€‚ä¸Šéƒ¨ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®ã€5) åˆ¶ç´„ä¸‹ã§ã®è³‡æºé…åˆ†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚"
    },
    {
        "name": "stakeholder",
        "keywords": ["é–¢ä¿‚è€…", "ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ", "å…±æœ‰ãƒ†ãƒ³ãƒ—ãƒ¬"],
        "message": None
    }
]

QUAL_SAMPLE_TEXTS = [
    {"source": "åšåŠ´çœ_åœ°åŸŸåŒ»ç™‚æ§‹æƒ³ãƒ’ã‚¢ãƒªãƒ³ã‚°2023-07", "text": "éƒ½å¸‚éƒ¨ã«åŒ»å¸«ãŒé›†ä¸­ã—ã€åœ°æ–¹ã®å¤œé–“æ•‘æ€¥ã§å—å…¥æ‹’å¦ãŒç›¸æ¬¡ã„ã§ã„ã‚‹ã€‚"},
    {"source": "çœŒè­°ä¼š_åŒ»ç™‚æä¾›ä½“åˆ¶å§”å“¡ä¼š_è­°äº‹éŒ²2024-03", "text": "åŒ»å¸«ãŒéè‡¨åºŠæ¥­å‹™ã«è¿½ã‚ã‚Œåˆè¨ºå¾…æ©ŸãŒé•·æœŸåŒ–ã€‚ICTæ´»ç”¨ãŒé€²ã‚“ã§ã„ãªã„ã€‚"},
    {"source": "åœ°åŸŸæ•‘æ€¥æ¬é€å®Ÿç¸¾ãƒ¬ãƒãƒ¼ãƒˆ2024", "text": "é«˜é½¢è€…ãŒå¤šã„åœ°åŸŸãªã®ã«ãƒ‰ã‚¯ã‚¿ãƒ¼ãƒ˜ãƒªãŒé ãã€æ¬é€æ™‚é–“ãŒ1æ™‚é–“ä»¥ä¸Šã‹ã‹ã‚‹ã€‚"},
    {"source": "åŒ»ç™‚ç¾å ´ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆè‡ªç”±è¨˜è¿°", "text": "åŒ»ç™‚ã‚¯ãƒ©ãƒ¼ã‚¯ãŒã„ãªã„ãŸã‚ã‚«ãƒ«ãƒ†å…¥åŠ›ã§æ®‹æ¥­ãŒå¸¸æ…‹åŒ–ã€‚"},
]

CAUSE_KEYWORDS = {
    "åŒ»å¸«ååœ¨": ["åŒ»å¸«", "ååœ¨", "éƒ½å¸‚", "åœ°æ–¹", "åã‚Š"],
    "éè‡¨åºŠæ¥­å‹™éå¤š": ["éè‡¨åºŠ", "äº‹å‹™", "ã‚¯ãƒ©ãƒ¼ã‚¯", "å…¥åŠ›", "æ®‹æ¥­"],
    "æ•‘æ€¥æ¬é€é…å»¶": ["æ•‘æ€¥", "æ¬é€", "ãƒ˜ãƒª", "å—å…¥", "å¾…æ©Ÿ"],
    "ICTä¸è¶³": ["ICT", "ãƒ‡ã‚¸ã‚¿ãƒ«", "é›»å­ã‚«ãƒ«ãƒ†", "DX"],
}
CAUSE_DATA_NEEDS = {
    "åŒ»å¸«ååœ¨": ["åœ°åŸŸåˆ¥åŒ»å¸«å±Šå‡ºç¥¨", "æ•‘æ€¥æ‹’å¦ä»¶æ•°ã®æ¨ç§»"],
    "éè‡¨åºŠæ¥­å‹™éå¤š": ["å‹¤å‹™è¡¨ã®æ™‚é–“é…åˆ†", "ã‚«ãƒ«ãƒ†å…¥åŠ›ãƒ­ã‚°"],
    "æ•‘æ€¥æ¬é€é…å»¶": ["æ¬é€æ™‚é–“ã¨è·é›¢ã®å¯¾ç…§", "ãƒ˜ãƒª/æ•‘æ€¥è»Šã®åˆ°ç€è¨˜éŒ²"],
    "ICTä¸è¶³": ["ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒç‡ãƒ­ã‚°", "è·å“¡ITãƒªãƒ†ãƒ©ã‚·ãƒ¼èª¿æŸ»"],
    "ãã®ä»–": ["è¿½åŠ ãƒ’ã‚¢ãƒªãƒ³ã‚°è¨˜éŒ²", "çµ±è¨ˆå±€ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿"]
}

POLICY_OPTION_DB = {
    "åŒ»å¸«ååœ¨": [
        {"name": "å¥¨å­¦é‡‘è¿”é‚„å…é™¤", "cost": 3.0, "effect": 12.0, "lag": 2, "risk": "ä¸­", "kpi_target": "æ•‘æ€¥å—å…¥ç‡(%)", "staff_need": 5, "evidence": "ç·å‹™çœ åœ°åŸŸæ å ±å‘Š 2022"},
        {"name": "ãƒ‰ã‚¯ã‚¿ãƒ¼ãƒãƒ³ã‚¯åˆ¶åº¦", "cost": 2.5, "effect": 8.0, "lag": 1, "risk": "ä¸­", "kpi_target": "åŒ»å¸«1äººã‚ãŸã‚Šæ‚£è€…æ•°(äºº)", "staff_need": 3, "evidence": "åŒ—æµ·é“ãƒ‰ã‚¯ã‚¿ãƒ¼ãƒãƒ³ã‚¯"}
    ],
    "éè‡¨åºŠæ¥­å‹™éå¤š": [
        {"name": "åŒ»ç™‚ã‚¯ãƒ©ãƒ¼ã‚¯å¢—å“¡", "cost": 1.5, "effect": 7.0, "lag": 0, "risk": "ä½", "kpi_target": "åˆè¨ºå¾…æ©Ÿæ—¥æ•°(æ—¥)", "staff_need": 8, "evidence": "åšåŠ´ç§‘ç ” ICTæ´»ç”¨å ±å‘Š"},
        {"name": "ICTåŠ¹ç‡åŒ–", "cost": 2.0, "effect": 9.0, "lag": 1, "risk": "ä½", "kpi_target": "åˆè¨ºå¾…æ©Ÿæ—¥æ•°(æ—¥)", "staff_need": 4, "evidence": "æˆé•·æˆ¦ç•¥ 2023"}
    ],
    "æ•‘æ€¥æ¬é€é…å»¶": [
        {"name": "ãƒ‰ã‚¯ã‚¿ãƒ¼ãƒ˜ãƒªå…±åŒé‹èˆª", "cost": 3.5, "effect": 11.0, "lag": 1, "risk": "ä¸­", "kpi_target": "æ•‘æ€¥å—å…¥ç‡(%)", "staff_need": 6, "evidence": "æ–°æ½ŸçœŒãƒ˜ãƒªæ•´å‚™"}
    ],
    "ICTä¸è¶³": [
        {"name": "é éš”ç”»åƒè¨ºæ–­ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯", "cost": 2.2, "effect": 8.5, "lag": 1, "risk": "ä¸­", "kpi_target": "æ•‘æ€¥å—å…¥ç‡(%)", "staff_need": 4, "evidence": "åŒ—æµ·é“é éš”åŒ»ç™‚"}
    ],
}

SCENARIO_TEMPLATES = [
    {"name": "A: æˆé•·", "budget": 8.0, "staff_limit": 30, "start_year": 2025, "duration": 6, "growth": 0.02, "lag_multiplier": 1.0, "discount_rate": 0.02},
    {"name": "B: ç¨åæ¸›", "budget": 5.0, "staff_limit": 20, "start_year": 2025, "duration": 6, "growth": -0.01, "lag_multiplier": 1.2, "discount_rate": 0.01},
]

RISK_SAMPLE = [
    {"risk": "è²¡æ”¿çŠ¶æ³æ‚ªåŒ–", "probability": 0.3, "impact": -4.0, "mitigation": "äº¤ä»˜ç¨ã®å¼¾åŠ›é‹ç”¨"},
    {"risk": "äººæç¢ºä¿å¤±æ•—", "probability": 0.4, "impact": -6.0, "mitigation": "æ°‘é–“å§”è¨—ã¨ç ”ä¿®å……å®Ÿ"},
]

# --------------------
# æ±ç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# --------------------
def now_str(): return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
def shorten(txt: str, n: int=160) -> str:
    if txt is None: return ""
    s = str(txt).replace("\n"," ")
    return s if len(s)<=n else s[:n]+"â€¦"
def normalize_message(m: dict) -> dict:
    return {"id": m.get("id", str(uuid.uuid4())), "t": m.get("t", now_str()),
            "role": m.get("role", "assistant"), "content": m.get("content",""),
            **{k:v for k,v in m.items() if k not in {"id","t","role","content"}}}

# --------------------
# å¯è¦–åŒ–
# --------------------
def bubble_chart(df: pd.DataFrame) -> go.Figure:
    if df is None or df.empty: return go.Figure()
    fig = px.scatter(df, x="ã‚³ã‚¹ãƒˆ(å„„å††)", y="åŠ¹æœ(ä¸­ä½)", size="åŠ¹æœ(ä¸­ä½)", color="ãƒªã‚¹ã‚¯",
                     text="æ–½ç­–", hover_data=df.columns, size_max=60)
    fig.update_traces(textposition="top center")
    fig.update_layout(title="è²»ç”¨å¯¾åŠ¹æœãƒãƒƒãƒ—", xaxis_title="ã‚³ã‚¹ãƒˆ(å„„å††)", yaxis_title="åŠ¹æœ(ä¸­ä½)")
    return fig

def band_chart(
    years: List[int],
    base: List[float],
    low: List[float],
    high: List[float],
    thr: Optional[float],
    y_title: str,
    extra_thresholds: Optional[List[Dict[str, Any]]] = None,
) -> go.Figure:
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=years, y=high, name="Best", mode="lines"))
    fig.add_trace(go.Scatter(x=years, y=low,  name="Worst", mode="lines", fill="tonexty"))
    fig.add_trace(go.Scatter(x=years, y=base, name="Base", mode="lines+markers"))
    if extra_thresholds:
        for th in extra_thresholds:
            val = th.get("value")
            label = th.get("label") or "Threshold"
            if val is not None:
                fig.add_hline(y=val, line_dash="dash", annotation_text=label)
    elif thr is not None:
        fig.add_hline(y=thr, line_dash="dash", annotation_text=f"Threshold={thr}")
    fig.update_layout(title="KPIäºˆæ¸¬ãƒ¬ãƒ³ã‚¸", xaxis_title="Year", yaxis_title=y_title)
    return fig

def logic_model_figure() -> go.Figure:
    nodes = {"èª²é¡Œ": (0.05,0.5), "Input(äºˆç®—/äººå“¡)": (0.25,0.5), "Activity(æ–½ç­–å®Ÿè¡Œ)": (0.45,0.5),
             "Output(çŸ­æœŸ)": (0.65,0.5), "Outcome(KPI)": (0.85,0.5), "Impact(ç¤¾ä¼šåŠ¹æœ)": (0.95,0.5)}
    fig = go.Figure()
    for name,(x,y) in nodes.items():
        fig.add_trace(go.Scatter(x=[x],y=[y],mode="markers+text",text=[name],textposition="bottom center",
                                 marker=dict(size=14),name=name,hoverinfo="text"))
    edges=[("èª²é¡Œ","Input(äºˆç®—/äººå“¡)",""),("Input(äºˆç®—/äººå“¡)","Activity(æ–½ç­–å®Ÿè¡Œ)","å®Ÿè£…"),
           ("Activity(æ–½ç­–å®Ÿè¡Œ)","Output(çŸ­æœŸ)","é”æˆ"),("Output(çŸ­æœŸ)","Outcome(KPI)","æ³¢åŠ"),
           ("Outcome(KPI)","Impact(ç¤¾ä¼šåŠ¹æœ)","é•·æœŸ")]
    for s,d,l in edges:
        x0,y0=nodes[s]; x1,y1=nodes[d]
        fig.add_annotation(x=x1,y=y1,ax=x0,ay=y0,showarrow=True,arrowhead=3,arrowsize=1,arrowwidth=1,text=l)
    fig.update_layout(title="Logic Model", xaxis=dict(visible=False), yaxis=dict(visible=False), showlegend=False, height=420)
    return fig

# --------------------
# EBPM è¨ˆç®—
# --------------------
def greedy_allocation(candidates: pd.DataFrame, budget: float) -> Tuple[pd.DataFrame, float, float]:
    if candidates is None or candidates.empty: return pd.DataFrame(), 0.0, 0.0
    df=candidates.copy(); df["eff_ratio"]=df["åŠ¹æœ(ä¸­ä½)"]/df["ã‚³ã‚¹ãƒˆ(å„„å††)"].replace(0,np.nan)
    df=df.sort_values("eff_ratio",ascending=False)
    picked=[]; cost_sum=0.0; eff_sum=0.0
    for _,r in df.iterrows():
        if cost_sum + r["ã‚³ã‚¹ãƒˆ(å„„å††)"] <= budget:
            picked.append(r); cost_sum+=r["ã‚³ã‚¹ãƒˆ(å„„å††)"]; eff_sum+=r["åŠ¹æœ(ä¸­ä½)"]
    return pd.DataFrame(picked), float(cost_sum), float(eff_sum)

def simulate_kpi(years: List[int], base_start: float, drift: float, policies: List[dict], lag_profile: Dict[int,float], noise=0.0) -> List[float]:
    vals=[]; states=[{"e":p["effect"],"lag":p["lag"],"age":0} for p in policies]
    for i,_ in enumerate(years):
        base=base_start+drift*i; yearly=0.0
        for s in states:
            idx = max(0, min(max(lag_profile), s["age"]-s["lag"]))
            w = lag_profile.get(idx, 0.0)
            yearly += s["e"]*max(0.0,w); s["age"]+=1
        vals.append(base+yearly+(np.random.normal(0,noise) if noise>0 else 0.0))
    return vals


def _to_float(val: Any) -> Optional[float]:
    try:
        if val is None: return None
        return float(val)
    except (TypeError, ValueError):
        return None


def threshold_breaches(years: List[int], low: List[float], high: List[float], constraint: Dict[str, Any]) -> List[str]:
    breaches: List[str] = []
    thr_value = _to_float(constraint.get("threshold_hint"))
    if thr_value is None:
        return breaches
    th_type = (constraint.get("threshold_type") or "min").lower()
    unit = constraint.get("unit") or ""
    name = constraint.get("name") or "KPI"
    if th_type == "min":
        for y, val in zip(years, low):
            if val < thr_value:
                breaches.append(f"{y}å¹´ã« {name} ãŒæœ€ä½å€¤ {thr_value}{unit} ã‚’ä¸‹å›ã‚‹æƒ³å®š ({val:.1f})")
                break
    elif th_type == "max":
        for y, val in zip(years, high):
            if val > thr_value:
                breaches.append(f"{y}å¹´ã« {name} ãŒä¸Šé™ {thr_value}{unit} ã‚’è¶…éã™ã‚‹æƒ³å®š ({val:.1f})")
                break
    return breaches


def load_qualitative_entries(files: List[Any]) -> List[Dict[str, str]]:
    entries: List[Dict[str, str]] = []
    for f in files or []:
        try:
            text = f.read().decode("utf-8")
        except Exception:
            continue
        for line in text.splitlines():
            line = line.strip()
            if not line:
                continue
            entries.append({"source": f.name, "text": line})
    return entries


def detect_cause_keyword(text: str) -> str:
    if not text:
        return "ãã®ä»–"
    t = text.lower()
    for cause, keywords in CAUSE_KEYWORDS.items():
        for k in keywords:
            if k.lower() in t:
                return cause
    return "ãã®ä»–"


def analyze_qualitative(entries: List[Dict[str, str]]) -> List[Dict[str, Any]]:
    rows: List[Dict[str, Any]] = []
    counter = Counter()
    for i, entry in enumerate(entries):
        cause = detect_cause_keyword(entry.get("text", ""))
        counter[cause] += 1
        rows.append({
            "quote_id": f"Q{i+1}",
            "source": entry.get("source", ""),
            "quote": entry.get("text", ""),
            "cause": cause,
            "cluster_lv1": cause,
            "cluster_lv2": cause,
            "importance": 1,
            "evidence_link": entry.get("source", "")
        })
    for row in rows:
        row["importance"] = counter[row["cause"]]
    return rows


def summarize_hypotheses(rows: List[Dict[str, Any]]) -> Tuple[pd.DataFrame, List[Dict[str, Any]]]:
    if not rows:
        return pd.DataFrame(), []
    df = pd.DataFrame(rows)
    pivot = df.groupby("cluster_lv1").agg({"importance": "max", "quote_id": "count"}).rename(columns={"quote_id": "frequency"}).reset_index()
    pivot = pivot.sort_values("frequency", ascending=False)
    evidence_gaps = [
        {"cause": r["cluster_lv1"], "issue": "ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒªãƒ³ã‚¯æœªè¨­å®š"}
        for r in rows if not r.get("evidence_link")
    ]
    return pivot, evidence_gaps


def generate_policy_options_from_hypotheses(hypotheses: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    options: List[Dict[str, Any]] = []
    seen = set()
    for h in hypotheses or []:
        cause = h.get("cluster_lv1") or h.get("cause")
        for opt in POLICY_OPTION_DB.get(cause, []):
            key = opt["name"]
            if key in seen:
                continue
            seen.add(key)
            options.append({
                "æ–½ç­–": opt.get("name"),
                "åŸå› ã‚«ãƒ†ã‚´ãƒª": cause,
                "ã‚³ã‚¹ãƒˆ(å„„å††)": opt.get("cost", 0.0),
                "åŠ¹æœ(ä¸­ä½)": opt.get("effect", 0.0),
                "åŠ¹æœ(æ‚²è¦³)": round(opt.get("effect", 0.0) * 0.7, 1),
                "åŠ¹æœ(æ¥½è¦³)": round(opt.get("effect", 0.0) * 1.2, 1),
                "ãƒ©ã‚°(å¹´)": opt.get("lag", 0),
                "ã‚¹ã‚¿ãƒƒãƒ•éœ€è¦": opt.get("staff_need", 0),
                "KPIç´ä»˜ã‘": opt.get("kpi_target", ""),
                "ãƒªã‚¹ã‚¯": opt.get("risk", "ä¸­"),
                "æ ¹æ‹ ": opt.get("evidence", ""),
            })
    return options


def optimize_scenario_allocation(options: pd.DataFrame, budget: float, staff_limit: float) -> pd.DataFrame:
    if options is None or options.empty:
        return pd.DataFrame()
    df = options.copy()
    if "ã‚¹ã‚¿ãƒƒãƒ•éœ€è¦" not in df.columns:
        df["ã‚¹ã‚¿ãƒƒãƒ•éœ€è¦"] = 0
    df["ã‚¹ã‚¿ãƒƒãƒ•éœ€è¦"] = df["ã‚¹ã‚¿ãƒƒãƒ•éœ€è¦"].fillna(0)
    df["eff_ratio"] = df["åŠ¹æœ(ä¸­ä½)"] / df["ã‚³ã‚¹ãƒˆ(å„„å††)"].replace(0, np.nan)
    df = df.sort_values("eff_ratio", ascending=False)
    picked = []
    cost_sum = 0.0
    staff_sum = 0.0
    for _, row in df.iterrows():
        cost = row["ã‚³ã‚¹ãƒˆ(å„„å††)"]
        staff = row.get("ã‚¹ã‚¿ãƒƒãƒ•éœ€è¦", 0)
        if cost_sum + cost <= budget and staff_sum + staff <= staff_limit:
            picked.append(row)
            cost_sum += cost
            staff_sum += staff
    return pd.DataFrame(picked)


def simulate_scenario(years: List[int], scenario: Dict[str, Any], selected: pd.DataFrame) -> Dict[str, Any]:
    lag_profile = {0:0.0,1:0.4,2:0.7,3:1.0}
    start = scenario.get("start_year", years[0])
    base_start = 70.0 + scenario.get("growth", 0.0) * 100
    drift = scenario.get("growth", 0.0) * 50
    sel_df = selected if isinstance(selected, pd.DataFrame) else pd.DataFrame()
    policies = []
    for _, r in sel_df.iterrows():
        policies.append({"effect": r.get("åŠ¹æœ(ä¸­ä½)",0.0), "lag": int(r.get("ãƒ©ã‚°(å¹´)",0))})
    mid = simulate_kpi(years, base_start, drift, policies, lag_profile)
    low = [v * 0.9 for v in mid]
    high = [v * 1.1 for v in mid]
    return {"years": years, "mid": mid, "low": low, "high": high}


def calc_risk_exposure(risks: List[Dict[str, Any]], picked: pd.DataFrame) -> pd.DataFrame:
    if not risks:
        return pd.DataFrame()
    df = pd.DataFrame(risks)
    df["expected_impact"] = df.get("probability", 0).astype(float) * df.get("impact", 0).astype(float)
    return df


def find_contention_points(hypotheses: List[Dict[str, Any]]) -> List[str]:
    counter = Counter()
    for h in hypotheses or []:
        counter[h.get("cluster_lv1", "")] += 1
    if len(counter) <= 1:
        return []
    most_common = counter.most_common(3)
    return [f"è«–ç‚¹: {name}ï¼ˆè¨€åŠ {freq} ä»¶ï¼‰" for name, freq in most_common]


def find_evidence_gaps(hypotheses: List[Dict[str, Any]]) -> List[str]:
    gaps = []
    for h in hypotheses or []:
        if not h.get("evidence_link"):
            gaps.append(f"{h.get('quote_id')} {h.get('cluster_lv1')} : å‡ºå…¸ä¸æ˜")
    return gaps


def fallback_gap_analysis(rows: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
   _entries = []
   for r in rows or []:
       cause = r.get("cluster_lv1") or r.get("cause") or "ãã®ä»–"
       needs = CAUSE_DATA_NEEDS.get(cause, CAUSE_DATA_NEEDS["ãã®ä»–"])
       _entries.append({
           "hypothesis": cause,
           "concern": "å®šé‡ãƒ‡ãƒ¼ã‚¿ã‚„æ¯”è¼ƒå¯¾è±¡ãŒä¸è¶³ã—ã¦ã„ã¾ã™",
           "needed_data": needs,
           "priority": "medium"
       })
   return _entries

# --------------------
# ã‚»ãƒƒã‚·ãƒ§ãƒ³
# --------------------
def _init_state():
    if "messages" not in st.session_state: st.session_state.messages=[]
    else: st.session_state.messages=[normalize_message(m) for m in st.session_state.messages]
    if "sessions" not in st.session_state: st.session_state.sessions=[]
    if "current_session_id" not in st.session_state: st.session_state.current_session_id=str(uuid.uuid4())
    if "context" not in st.session_state:
        st.session_state.context = {
            "domain": None, "kpi": None, "thr": None, "budget": None,
            "candidates": None, "picked": None, "base_start": 70.0, "drift": 0.0,
            "years": list(range(2025, 2031)),
            # Agents/Research
            "agents": None,
            "primer": None,
            "rs_result": None,
            "kpi_seed_fragments": [],
            "kpi_catalog": None,
            "effect_models": [],
            "per_node_timeseries": {},
            "topic_map": None,
            "topic_layer_hits": None,
            "policy_hypotheses": None,
            "kpi_templates": [],
            "kpi_constraints": [],
            "kpi_targets": [],
            "kpi_threshold_type": None,
            "qual_entries": [],
            "hypothesis_clusters": [],
            "policy_options": [],
            "scenario_configs": [],
            "scenario_results": {},
            "risk_register": [],
            "evidence_gaps": [],
            "contention_points": [],
            "hypothesis_gap_analysis": [],
            "policy_stage": "å•é¡Œæ„è­˜",
            "stage_notes": {},
            "decision_notes": "",
            "feedback_log": [],
            "stakeholder_templates": [],
            "agent_competition": {},
            "causality": None
        }
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼å†…ã®è¨­å®šã«è¿½è¨˜
        st.session_state.restrict_rs = st.checkbox("RSã‚·ã‚¹ãƒ†ãƒ é™å®šï¼ˆæ”¿ç­–æ¤œç´¢ï¼‰", value=True)
        # ä»£æ›¿æ¡ˆã®æ•°ã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿æŒï¼ˆå¾Œæ®µã®å‚ç…§ã§ NameError ã‚’é¿ã‘ã‚‹ï¼‰
        if "n_alts" not in st.session_state:
            st.session_state.n_alts = 3
        st.number_input(
            "ä»£æ›¿æ¡ˆã®æ•°ï¼ˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰", min_value=1, max_value=5, value=st.session_state.n_alts, step=1, key="n_alts"
        )
    if "openai_api_key" not in st.session_state: st.session_state.openai_api_key=""
    if "tavily_api_key" not in st.session_state: st.session_state.tavily_api_key=""
    if "use_web_search" not in st.session_state: st.session_state.use_web_search=True
    if "show_agent_blocks" not in st.session_state: st.session_state.show_agent_blocks=True
_init_state()

def log_message(role: str, content: str, extra: dict | None = None):
    msg = {"id": str(uuid.uuid4()), "t": now_str(), "role": role, "content": content}
    if extra: msg.update(extra)
    st.session_state.messages.append(normalize_message(msg))

def start_new_conversation():
    started_at = now_str()
    if st.session_state.messages:
        first = normalize_message(st.session_state.messages[0]); started_at = first.get("t", now_str())
    st.session_state.sessions.append({
        "id": st.session_state.current_session_id, "started_at": started_at, "ended_at": now_str(),
        "messages": [normalize_message(m) for m in st.session_state.messages],
        "context": st.session_state.context.copy(),
    })
    st.session_state.current_session_id = str(uuid.uuid4())
    st.session_state.messages = []
    st.session_state.context.update({
        "domain": None, "kpi": None, "thr": None, "budget": None, "candidates": None, "picked": None,
        "base_start": 70.0, "drift": 0.0, "years": list(range(2025, 2031)),
        "agents": None, "primer": None, "rs_result": None, "kpi_seed_fragments": [],
        "kpi_catalog": None, "effect_models": [], "per_node_timeseries": {},
        "topic_map": None, "topic_layer_hits": None, "policy_hypotheses": None,
        "kpi_templates": [], "kpi_constraints": [], "kpi_threshold_type": None,
        "kpi_targets": [],
        "qual_entries": [], "hypothesis_clusters": [], "policy_options": [],
        "scenario_configs": [], "scenario_results": {}, "risk_register": [],
        "evidence_gaps": [], "contention_points": [], "hypothesis_gap_analysis": [],
        "policy_stage": "å•é¡Œæ„è­˜", "stage_notes": {}, "decision_notes": "", "feedback_log": [],
        "stakeholder_templates": [], "agent_competition": {},
        "causality": None
    })


def render_topic_map(topic_map: Dict[str, Any]):
    layers = topic_map.get("topic_layers") or []
    if not layers:
        st.info("è«–ç‚¹ãƒãƒƒãƒ—ãŒã¾ã ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    def bullet(text: str, level: int = 0):
        indent = "&nbsp;" * (level * 4)
        st.markdown(f"{indent}â€¢ {text}", unsafe_allow_html=True)

    for node in layers:
        sub_name = node.get("subproblem") or "ã‚µãƒ–ãƒ—ãƒ­ãƒ–ãƒ¬ãƒ "
        overview = node.get("overview") or ""
        with st.expander(f"ğŸ“‚ {sub_name}", expanded=False):
            if overview:
                st.markdown(f"> {overview}")
            for layer in node.get("layers", []) or []:
                tier = layer.get("tier", "")
                label = layer.get("label", "")
                focus = layer.get("policy_focus", "")
                bullet(f"[{tier.upper()}] {label} â€• {focus}", level=0)
                if layer.get("keywords"):
                    bullet("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: " + ", ".join(layer["keywords"]), level=1)
                if layer.get("angles"):
                    bullet("æ¤œè¨è§’åº¦: " + ", ".join(layer["angles"]), level=1)
                sample = layer.get("sample_queries") or {}
                policy_q = sample.get("policy") or []
                evidence_q = sample.get("evidence") or []
                if policy_q:
                    bullet("æ”¿ç­–æ¤œç´¢: " + " / ".join(policy_q), level=1)
                if evidence_q:
                    bullet("ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹æ¤œç´¢: " + " / ".join(evidence_q), level=1)
                for child in layer.get("child_nodes") or []:
                    child_label = child.get("label", "")
                    scope = child.get("scope", "")
                    bullet(f"{child_label} ({scope})", level=1)
                    if child.get("signals"):
                        bullet("æŠŠæ¡ã—ãŸã„æŒ‡æ¨™: " + ", ".join(child["signals"]), level=2)
                    if child.get("sample_sources"):
                        bullet("å‚è€ƒã‚½ãƒ¼ã‚¹: " + ", ".join(child["sample_sources"]), level=2)
    gq = topic_map.get("global_queries") or {}
    if gq:
        st.markdown("**ã‚°ãƒ­ãƒ¼ãƒãƒ«æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**")
        if gq.get("broad"):
            st.write("åºƒç¾©:", ", ".join(gq["broad"]))
        if gq.get("focused"):
            st.write("é‡ç‚¹:", ", ".join(gq["focused"]))


def render_policy_hypotheses(hypotheses: Dict[str, List[Dict[str, Any]]]):
    if not hypotheses:
        st.info("æ”¿ç­–ä»®èª¬ãŒã¾ã ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    for sub, layers in hypotheses.items():
        with st.expander(f"ğŸ§  {sub}", expanded=False):
            for layer in layers:
                st.markdown(f"**[{layer.get('tier','')}] {layer.get('label','')}**")
                for i, hyp in enumerate(layer.get("hypotheses", []), start=1):
                    st.markdown(f"- ({i}) {hyp.get('name','ä»®èª¬')}")
                    st.caption(hyp.get("summary", ""))
                    if hyp.get("expected_effect"):
                        st.write("ã€€åŠ¹æœæƒ³å®š:", hyp["expected_effect"])
                    if hyp.get("kpi"):
                        st.write("ã€€KPI:", ", ".join(hyp["kpi"]))
                    if hyp.get("evidence"):
                        st.write("ã€€å‚è€ƒ:", ", ".join(hyp["evidence"]))


def render_policy_actions(policies: List[Dict[str, Any]]):
    if not policies:
        st.info("æ¡ç”¨æ”¿ç­–å€™è£œãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    df = pd.DataFrame(policies)
    if not df.empty:
        st.dataframe(
            df.rename(columns={"name": "æ–½ç­–", "description": "æ¦‚è¦", "kpi_links": "ç´ä»˜KPI"}),
            use_container_width=True,
        )
    else:
        st.json(policies)


def render_logic_tree_graph(tree: Dict[str, Any]):
    nodes = (tree or {}).get("nodes") or []
    edges = (tree or {}).get("edges") or []
    if not nodes:
        st.info("ãƒ­ã‚¸ãƒƒã‚¯ãƒ„ãƒªãƒ¼æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        return
    dot = graphviz.Digraph()
    ids = []
    for node in nodes:
        node_id = str(node.get("id") or node.get("label") or f"N{len(ids)+1}")
        ids.append(node_id)
        label = node.get("label") or node_id
        detail = node.get("detail") or ""
        dot.node(node_id, f"{label}\n{detail}")
    for edge in edges:
        src = str(edge.get("from"))
        dst = str(edge.get("to"))
        if not src or not dst:
            continue
        ev = edge.get("evidence", "")
        level = (edge.get("evidence_level") or "medium").lower()
        conflict = edge.get("conflict") or ""
        color = {"high": "#2ca02c", "medium": "#ff7f0e", "low": "#d62728"}.get(level, "#7f7f7f")
        edge_label = ev
        if conflict:
            edge_label = f"{ev}\nâš  {conflict}" if ev else f"âš  {conflict}"
        dot.edge(src, dst, label=edge_label, color=color)
    st.graphviz_chart(dot, use_container_width=True)


def _normalize_kpi_links(value: Any) -> List[str]:
    if value is None:
        return []
    if isinstance(value, list):
        return [str(v).strip() for v in value if str(v).strip()]
    if isinstance(value, str):
        items = [s.strip() for s in re.split(r"[,/ã€;|]", value) if s.strip()]
        if not items and value.strip():
            items = [value.strip()]
        return items
    return []


def get_kpi_targets(ctx: Dict[str, Any]) -> List[str]:
    if not ctx:
        return []
    targets = ctx.get("kpi_targets") or []
    if targets:
        return [t for t in targets if t]
    fallback = ctx.get("kpi")
    return [fallback] if fallback else []


def get_primary_kpi_name(ctx: Dict[str, Any]) -> Optional[str]:
    targets = get_kpi_targets(ctx)
    return targets[0] if targets else None


def set_kpi_targets(ctx: Dict[str, Any], targets: List[str]):
    clean = [t for t in targets if t]
    ctx["kpi_targets"] = clean
    ctx["kpi"] = clean[0] if clean else None


def epsilon_constraint_allocation(effect_matrix: np.ndarray, y_base: np.ndarray, budget: float, epsilons: np.ndarray):
    m, n = effect_matrix.shape
    solutions = {}
    for target in range(m):
        model = pulp.LpProblem(f"Maximize_KPI_{target}", pulp.LpMaximize)
        x = [pulp.LpVariable(f"x_{i}", lowBound=0) for i in range(n)]
        y = [y_base[k] + pulp.lpSum(effect_matrix[k][i] * x[i] for i in range(n)) for k in range(m)]
        model += pulp.lpSum(x) == budget
        for k in range(m):
            if k != target:
                model += y[k] >= epsilons[k]
        model += y[target]
        model.solve(pulp.PULP_CBC_CMD(msg=0))
        x_sol = [round(pulp.value(var) or 0.0, 4) for var in x]
        y_sol = [round(pulp.value(val) or 0.0, 4) for val in y]
        solutions[target] = {"allocation": x_sol, "KPI_pred": y_sol}
    return solutions


def build_effect_inputs(state: Dict[str, Any]):
    app_ctx: Dict[str, Any]
    if hasattr(state, "context"):
        app_ctx = state.context
    elif isinstance(state, dict):
        app_ctx = state
    else:
        app_ctx = {}
    complex_ctx = app_ctx.setdefault("complex", {})

    constraints = complex_ctx.get("kpi_constraints") or app_ctx.get("kpi_constraints") or []
    if not constraints:
        domain = app_ctx.get("domain") or next(iter(KPI_CATALOG.keys()))
        kpis = KPI_CATALOG.get(domain) or next(iter(KPI_CATALOG.values()))
        defaults = []
        base = 70.0
        for idx, name in enumerate(kpis):
            defaults.append({
                "name": name,
                "definition": f"{name} ã®é”æˆåº¦",
                "unit": "%",
                "direction": "up",
                "threshold_type": "min",
                "threshold_hint": round(base + idx * 5, 1),
                "data_source": "è‡ªå‹•ææ¡ˆã‚µãƒ³ãƒ—ãƒ«",
                "legal_floor": "",
                "rationale": "ã‚¹ãƒ†ãƒƒãƒ—æœªå…¥åŠ›ã®ãŸã‚è‡ªå‹•è£œå®Œ",
                "baseline": round(base - 5, 1),
            })
        complex_ctx["kpi_constraints"] = defaults
        app_ctx["kpi_constraints"] = defaults
        if defaults:
            set_kpi_targets(app_ctx, [defaults[0].get("name")] if defaults[0].get("name") else [])
        constraints = defaults

    policies = complex_ctx.get("policy_options") or []
    if not policies:
        auto_policies: List[Dict[str, Any]] = []
        for cause, opts in POLICY_OPTION_DB.items():
            for opt in opts:
                auto_policies.append({
                    "æ–½ç­–": opt.get("name"),
                    "åŸå› ã‚«ãƒ†ã‚´ãƒª": cause,
                    "ã‚³ã‚¹ãƒˆ(å„„å††)": opt.get("cost", 0.0),
                    "åŠ¹æœ(ä¸­ä½)": opt.get("effect", 0.0),
                    "åŠ¹æœ(æ‚²è¦³)": round(opt.get("effect", 0.0) * 0.7, 1),
                    "åŠ¹æœ(æ¥½è¦³)": round(opt.get("effect", 0.0) * 1.2, 1),
                    "ãƒ©ã‚°(å¹´)": opt.get("lag", 0),
                    "ã‚¹ã‚¿ãƒƒãƒ•éœ€è¦": opt.get("staff_need", 0),
                    "KPIç´ä»˜ã‘": opt.get("kpi_target", ""),
                    "ãƒªã‚¹ã‚¯": opt.get("risk", "ä¸­"),
                    "æ ¹æ‹ ": opt.get("evidence", ""),
                })
        complex_ctx["policy_options"] = auto_policies
        policies = auto_policies

    kpi_names = [c.get("name") for c in constraints if c.get("name")]
    if not kpi_names:
        return None
    n = len(policies)
    effect = np.zeros((len(kpi_names), n))
    kpi_index = {name: idx for idx, name in enumerate(kpi_names)}
    for j, opt in enumerate(policies):
        linked = opt.get("KPIç´ä»˜ã‘") or kpi_names
        value = float(opt.get("åŠ¹æœ(ä¸­ä½)") or 0.0)
        if not linked:
            linked = kpi_names
        for name in linked:
            idx = kpi_index.get(name)
            if idx is not None:
                effect[idx, j] = value / max(1, len(linked))
    y_base = np.array([
        float(c.get("baseline") or c.get("threshold_hint") or 0.0)
        for c in constraints if c.get("name") in kpi_index
    ])
    if len(y_base) != len(kpi_names):
        y_base = np.array([float(c.get("threshold_hint") or 0.0) for c in constraints if c.get("name")])
    eps = np.array([
        float(c.get("threshold_hint") or y_base[i] if i < len(y_base) else 0.0)
        for i, c in enumerate(constraints) if c.get("name")
    ])
    budget = float(ctx.get("budget") or sum(float(opt.get("ã‚³ã‚¹ãƒˆ(å„„å††)") or 1.0) for opt in policies))
    policy_names = [opt.get("æ–½ç­–") or opt.get("name") or f"æ–½ç­–{idx+1}" for idx, opt in enumerate(policies)]
    return effect, y_base, eps, budget, kpi_names, policy_names
def local_critique(strategies: List[Dict[str, Any]]) -> Dict[str, Any]:
    reviews = []
    for strat in strategies or []:
        name = strat.get("name", "strategy")
        policies = strat.get("policies", [])
        kpis = [k for p in policies for k in p.get("expected_kpis", [])]
        reviews.append({
            "strategy_name": name,
            "strengths": [f"æ”¿ç­–æ•° {len(policies)} ä»¶ã‚’æŸã­ã¦ã„ã‚‹"],
            "weaknesses": ["ãƒ­ãƒ¼ã‚«ãƒ«æ‰¹è©•: ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹å¼·åº¦ã‚’ç¢ºèªã™ã‚‹å¿…è¦ã‚ã‚Š"],
            "trade_offs": ["å…¬å¹³æ€§ã¨å³åŠ¹æ€§ã®ãƒãƒ©ãƒ³ã‚¹"],
            "risks": ["å®Ÿè¡Œä½“åˆ¶ã®èª¿æ•´"],
            "mitigations": ["é–¢ä¿‚æ©Ÿé–¢ã¨ã®é€£çµ¡ä¼šã‚’è¨­å®š"],
            "unknowns": ["KPIãƒ‡ãƒ¼ã‚¿ã®æœ€æ–°æ€§"],
            "kpi_focus": list(dict.fromkeys(kpis))[:3],
        })
    return {
        "reviews": reviews,
        "cross_cutting_observations": ["ãƒ­ãƒ¼ã‚«ãƒ«æ‰¹è©•: ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹è©³ç´°ã¯LLMå®Ÿè¡Œæ™‚ã«è£œå®Œã—ã¦ãã ã•ã„"]
    }


def render_stage_guide(ctx: Dict[str, Any]):
    current = ctx.get("policy_stage", POLICY_STAGE_FLOW[0]["name"])
    st.markdown("### ğŸ§­ æ”¿ç­–ã‚¹ãƒ†ãƒ¼ã‚¸ã‚¬ã‚¤ãƒ‰")
    cols = st.columns(len(POLICY_STAGE_FLOW))
    for col, stage in zip(cols, POLICY_STAGE_FLOW):
        with col:
            is_active = stage["name"] == current
            st.button(
                f"{stage['name']}\n{stage['desc']}",
                type="primary" if is_active else "secondary",
                key=f"stage_btn_{stage['name']}",
                on_click=lambda s=stage['name']: ctx.update({"policy_stage": s})
            )
    hints = STAGE_ACTION_HINTS.get(current, [])
    if hints:
        st.info("ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¸æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: " + " / ".join(hints))


def build_stakeholder_template(ctx: Dict[str, Any]) -> str:
    domain = ctx.get("domain") or "æ”¿ç­–èª²é¡Œ"
    stage = ctx.get("policy_stage", "å•é¡Œæ„è­˜")
    targets = get_kpi_targets(ctx)
    primary_kpi = targets[0] if targets else (ctx.get("kpi") or "ä¸»è¦KPI")
    kpi_label = primary_kpi if len(targets) <= 1 else f"{primary_kpi} ã»ã‹{len(targets)-1}æŒ‡æ¨™"
    thr = ctx.get("thr")
    thr_text = f"ç›®æ¨™ {kpi_label} >= {thr}" if thr else f"{kpi_label} ã‚’æ”¹å–„"
    template = (
        f"ä»¶å: {domain} ã®é€²ã‚æ–¹ã«ã¤ã„ã¦\n"
        f"ç¾çŠ¶: {stage} æ®µéšã§ã®æ°—ã¥ãã¨è«–ç‚¹ã‚’å…±æœ‰ã—ã¾ã™ã€‚\n"
        f"KPIç›®ç·š: {thr_text}\n"
        "æ±‚ã‚ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: â‘ æœ€æ–°ãƒ‡ãƒ¼ã‚¿å…±æœ‰ â‘¡åˆæ„å½¢æˆã®ãŸã‚ã®ã‚³ãƒ¡ãƒ³ãƒˆ â‘¢è¿½åŠ æ‡¸å¿µç‚¹\n"
        "è¿”ä¿¡æœŸé™: â—‹æœˆâ—‹æ—¥ã¾ã§ã«ã‚³ãƒ¡ãƒ³ãƒˆã„ãŸã ã‘ã‚‹ã¨åŠ©ã‹ã‚Šã¾ã™ã€‚"
    )
    return template


def get_polaris_flow(ctx: Dict[str, Any]) -> Dict[str, Any]:
    return ctx.setdefault(
        "polaris_flow",
        {
            "stage": "ask_problem",
            "messages": [],
            "problem": "",
            "qual_entries": [],
            "policy_choice": None,
            "last_search_duration": None,
        },
    )


def polaris_log(ctx: Dict[str, Any], role: str, text: str, payload: Optional[Dict[str, Any]] = None):
    pf = get_polaris_flow(ctx)
    entry = {"role": role, "content": text, "ts": now_str()}
    if payload:
        entry["payload"] = payload
    pf["messages"].append(entry)
    pf["messages"] = pf["messages"][-60:]


def render_polaris_chat(ctx: Dict[str, Any]):
    pf = get_polaris_flow(ctx)
    for msg in pf["messages"]:
        with st.chat_message("assistant" if msg["role"] == "assistant" else "user"):
            st.markdown(msg["content"])
            payload = msg.get("payload")
            if payload:
                kind = payload.get("kind")
                label = payload.get("label")
                if kind == "table":
                    data = payload.get("data") or []
                    if data:
                        df = pd.DataFrame(data)
                        if label:
                            st.caption(label)
                        st.dataframe(df, use_container_width=True)
                elif kind == "strategies":
                    data = payload.get("data") or []
                    if label:
                        st.caption(label)
                    for strat in data:
                        st.markdown(f"**{strat.get('name','strateg y')}** ({strat.get('theme','')})  \n{shorten(strat.get('summary',''), 220)}")
                elif kind == "markdown":
                    if label:
                        st.caption(label)
                    st.markdown(payload.get("text", ""))


def _autofill_kpi_constraints(ctx: Dict[str, Any]) -> List[Dict[str, Any]]:
    refined = ctx["complex"].get("refined") or {}
    candidates = refined.get("refined_problem", {}).get("kpi_candidates") or []
    if not candidates:
        domain = ctx.get("domain") or next(iter(KPI_CATALOG.keys()))
        base = KPI_CATALOG.get(domain) or next(iter(KPI_CATALOG.values()))
        candidates = [{"name": name, "threshold_hint": 75 + idx * 3} for idx, name in enumerate(base)]
    constraints = []
    for idx, cand in enumerate(candidates):
        if isinstance(cand, str):
            name = cand
            threshold = 75 + idx * 2
            unit = "%"
            direction = "up"
        else:
            name = cand.get("name") or f"KPI{idx+1}"
            threshold = cand.get("threshold_hint") or (75 + idx * 2)
            unit = cand.get("unit") or "%"
            direction = cand.get("direction") or "up"
        constraints.append({
            "name": name,
            "definition": cand.get("definition") if isinstance(cand, dict) else "",
            "unit": unit,
            "direction": direction,
            "threshold_type": cand.get("threshold_type", "min") if isinstance(cand, dict) else "min",
            "threshold_hint": threshold,
            "data_source": cand.get("source", "POLARISæ¨å®š") if isinstance(cand, dict) else "POLARISæ¨å®š",
            "legal_floor": cand.get("legal_floor", "") if isinstance(cand, dict) else "",
            "rationale": cand.get("rationale", "") if isinstance(cand, dict) else "",
            "baseline": cand.get("baseline", threshold - 5) if isinstance(cand, dict) else threshold - 5,
        })
    return constraints[:5]


def advance_polaris_flow(ctx: Dict[str, Any]):
    pf = get_polaris_flow(ctx)
    while True:
        stage = pf.get("stage", "ask_problem")
        if stage == "refine":
            problem = pf.get("problem") or ctx["complex"].get("user_query")
            if not problem:
                pf["stage"] = "ask_problem"
                break
            with st.spinner("è©³ç´°åŒ–ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™â€¦"):
                refined = refine_problem(problem)
            ctx["complex"]["refined"] = refined
            ctx["complex"]["user_query"] = problem
            ctx["complex"].update({
                "workplan": None,
                "topic_map": None,
                "topic_layer_hits": None,
                "policy_hypotheses": None,
                "search_results": None,
                "strategies": [],
                "critique": None,
                "budgets": [],
                "qual_entries": [],
                "hypothesis_clusters": [],
                "policy_options": [],
                "scenario_configs": [],
                "scenario_results": {},
            })
            pf["stage"] = "kpi_proposal"
            summary = refined.get("refined_problem", {}).get("title") or "è©³ç´°åŒ–æ¸ˆã¿ã®æ”¿ç­–èª²é¡Œ"
            polaris_log(ctx, "assistant", f"æ”¿ç­–èª²é¡Œã‚’è©³ç´°åŒ–ã—ã¾ã—ãŸã€‚\n\n- ä¸»é¡Œ: **{summary}**\n- é‡ç‚¹è«–ç‚¹ã‚’æ•´ç†ã—ã¾ã—ãŸã€‚æ¬¡ã« KPI ã®å€™è£œã‚’æç¤ºã—ã¾ã™ã€‚")
            continue
        if stage == "kpi_proposal":
            constraints = _autofill_kpi_constraints(ctx)
            ctx["complex"]["kpi_constraints"] = constraints
            ctx["complex"]["kpi_templates"] = constraints
            ctx["kpi_constraints"] = constraints
            set_kpi_targets(ctx, [c["name"] for c in constraints if c.get("name")])
            table_data = [
                {
                    "KPI": c.get("name"),
                    "ç›®æ¨™": f"{c.get('threshold_hint')} {c.get('unit','')}".strip(),
                    "æ–¹å‘": "å‘ä¸Š" if (c.get("direction") or "up") == "up" else "æŠ‘åˆ¶",
                }
                for c in constraints
            ]
            polaris_log(
                ctx,
                "assistant",
                "ã€ŒKPIå€™è£œã®ææ¡ˆã€ã‚’è¡Œã„ã¾ã—ãŸã€‚\n\n2) KPIè¨­å®šã¨åˆ¶ç´„æ¡ä»¶ã®æ˜ç¢ºåŒ–ã‚’è¡Œã„ã¾ã—ã‚‡ã†ã€‚ãƒ†ãƒ¼ãƒ–ãƒ«ã§é–¾å€¤ã‚’èª¿æ•´ã—ãŸã‚‰ã€KPIè¨­å®šå®Œäº†ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚",
                payload={"kind": "table", "label": "KPIå€™è£œä¸€è¦§", "data": table_data},
            )
            pf["stage"] = "kpi_confirm"
            continue
        if stage == "qual_analyze":
            entries = pf.get("qual_entries")
            if not entries:
                pf["stage"] = "qual_prompt"
                break
            with st.spinner("è³ªçš„ãƒ‡ãƒ¼ã‚¿ã‚’KJæ³•çš„ã«æ•´ç†ã—ã¦ã„ã¾ã™â€¦"):
                rows = analyze_qualitative(entries)
            pivot, gaps = summarize_hypotheses(rows)
            ctx["complex"]["qual_entries"] = entries
            ctx["complex"]["hypothesis_clusters"] = rows
            ctx["complex"]["evidence_gaps"] = [g["issue"] if isinstance(g, dict) else str(g) for g in gaps]
            ctx["complex"]["contention_points"] = find_contention_points(rows)
            table = pivot.rename(columns={"cluster_lv1": "åŸå› ã‚¯ãƒ©ã‚¹ã‚¿", "frequency": "ä»¶æ•°", "importance": "é‡è¦åº¦"}).to_dict("records")
            polaris_log(
                ctx,
                "assistant",
                f"è³ªçš„ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã¾ã—ãŸã€‚ä»®èª¬ã‚¯ãƒ©ã‚¹ã‚¿æ•°: {len(pivot)}ã€‚åŸå› åˆ¥ã®æ–½ç­–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’åˆ—æŒ™ã—ã¾ã™ã€‚",
                payload={"kind": "table", "label": "ä»®èª¬ã‚¯ãƒ©ã‚¹ã‚¿æ¦‚è¦", "data": table},
            )
            pf["stage"] = "policy_auto"
            continue
        if stage == "policy_auto":
            hypotheses = ctx["complex"].get("hypothesis_clusters") or []
            options = generate_policy_options_from_hypotheses(hypotheses)
            if not options:
                options = [
                    {"æ–½ç­–": n, "åŸå› ã‚«ãƒ†ã‚´ãƒª": "å‚è€ƒ", "ã‚³ã‚¹ãƒˆ(å„„å††)": info["cost"], "åŠ¹æœ(ä¸­ä½)": info["effect"],
                     "åŠ¹æœ(æ‚²è¦³)": round(info["effect"]*0.7,1), "åŠ¹æœ(æ¥½è¦³)": round(info["effect"]*1.2,1),
                     "ãƒ©ã‚°(å¹´)": info["lag"], "ã‚¹ã‚¿ãƒƒãƒ•éœ€è¦": 5, "KPIç´ä»˜ã‘": get_primary_kpi_name(ctx),
                     "ãƒªã‚¹ã‚¯": info["risk"], "æ ¹æ‹ ": "POLARISãƒ©ã‚¤ãƒ–ãƒ©ãƒª"}
                    for n, info in POLICY_LIBRARY.items()
                ]
            ctx["complex"]["policy_options"] = options
            table = [
                {
                    "æ–½ç­–": opt.get("æ–½ç­–"),
                    "åŸå› ": opt.get("åŸå› ã‚«ãƒ†ã‚´ãƒª"),
                    "åŠ¹æœ(ä¸­ä½)": opt.get("åŠ¹æœ(ä¸­ä½)"),
                    "ã‚³ã‚¹ãƒˆ(å„„å††)": opt.get("ã‚³ã‚¹ãƒˆ(å„„å††)"),
                }
                for opt in options[:6]
            ]
            polaris_log(
                ctx,
                "assistant",
                f"åŸå› åˆ¥ã®æ–½ç­–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ {len(options)} ä»¶æŠ½å‡ºã—ã¾ã—ãŸã€‚ã“ã®æ–¹é‡ã§é€²ã‚ã¦ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿï¼ˆã¯ã„/ã„ã„ãˆã‚’é¸æŠï¼‰",
                payload={"kind": "table", "label": "æ–½ç­–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆæŠœç²‹ï¼‰", "data": table},
            )
            st.session_state.pop("polaris_policy_choice", None)
            pf["stage"] = "policy_confirm"
            continue
        if stage == "decompose_run":
            refined = ctx["complex"].get("refined")
            if not refined:
                pf["stage"] = "ask_problem"
                break
            with st.spinner("ã‚¿ã‚¹ã‚¯ã‚’åˆ†è§£ã—ã€è«–ç‚¹ã‚’éšå±¤åŒ–ã—ã¦ã„ã¾ã™â€¦"):
                workplan = decompose_work(refined.get("refined_problem", refined))
                try:
                    topic_map = explore_topics(ctx["complex"].get("user_query") or "", refined, workplan)
                except Exception:
                    topic_map = {}
            ctx["complex"]["workplan"] = workplan
            ctx["complex"]["topic_map"] = topic_map
            polaris_log(ctx, "assistant", "ã‚¿ã‚¹ã‚¯åˆ†è§£ã¨è«–ç‚¹ãƒãƒƒãƒ—ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚åˆ†è§£ã«åŸºã¥ãæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
            pf["stage"] = "search_run"
            continue
        if stage == "search_run":
            workplan = ctx["complex"].get("workplan")
            if not workplan:
                pf["stage"] = "decompose_run"
                continue
            start = time.time()
            status_placeholder = st.empty()
            with st.spinner("åˆ†è§£ã«åŸºã¥ãæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™â€¦"):
                search_res = run_searches(
                    workplan,
                    prefer_rs_system=st.session_state.restrict_rs,
                    user_query=ctx["complex"].get("user_query"),
                    refined_problem=ctx["complex"].get("refined"),
                    topic_map=ctx["complex"].get("topic_map"),
                )
            policy_hits = search_res.get("policy_hits", [])
            paper_hits = search_res.get("paper_hits", [])
            polaris_log(
                ctx,
                "assistant",
                "åˆ†è§£ã«åŸºã¥ãæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™â€¦",
                payload={
                    "kind": "table",
                    "label": "æ¤œç´¢é€”ä¸­ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
                    "data": [
                        {"ç¨®åˆ¥": "æ”¿ç­–ãƒ’ãƒƒãƒˆä»¶æ•°", "å€¤": len(policy_hits)},
                        {"ç¨®åˆ¥": "è«–æ–‡ãƒ’ãƒƒãƒˆä»¶æ•°", "å€¤": len(paper_hits)},
                    ],
                },
            )
            duration = time.time() - start
            ctx["complex"]["search_results"] = search_res
            if duration > 10 or not policy_hits:
                dummy_agent = DummyDataAgent()
                dummy = dummy_agent.run(
                    ctx["complex"].get("user_query") or "",
                    subproblem="policy",
                    data_type="policy",
                    count=3,
                )
                for hit in dummy.get("items", []):
                    policy_hits.append({
                        "title": hit.get("title", "Dummy Policy"),
                        "url": hit.get("url", "https://example.com/dummy"),
                        "snippet": hit.get("snippet", "ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ (æ”¿ç­–)"),
                        "rank": len(policy_hits) + 1,
                    })
                search_res["policy_hits"] = policy_hits
                polaris_log(ctx, "assistant", "æ¤œç´¢çµæœãŒ10ç§’ä»¥å†…ã«æƒã‚ãªã‹ã£ãŸãŸã‚ã€ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§è£œå®Œã—ã¾ã—ãŸã€‚")
            else:
                polaris_log(ctx, "assistant", f"{duration:.1f}ç§’ã§æ”¿ç­–å€™è£œ {len(policy_hits)} ä»¶ã€è«–æ–‡ {len(search_res.get('paper_hits', []))} ä»¶ã‚’å–å¾—ã—ã¾ã—ãŸã€‚è¤‡æ•°æ¡ˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
            pf["stage"] = "strategy_run"
            continue
        if stage == "strategy_run":
            refined = ctx["complex"].get("refined")
            workplan = ctx["complex"].get("workplan")
            search_res = ctx["complex"].get("search_results") or {}
            if not (refined and workplan and search_res):
                pf["stage"] = "search_run"
                continue
            with st.spinner("è¤‡æ•°ã®æ”¿ç­–æ¡ˆã‚’åˆæˆã—ã¦ã„ã¾ã™â€¦"):
                n_alts = int(st.session_state.get("n_alts", 3))
                strategies = synthesize_strategies(refined, workplan, search_res, n_alternatives=n_alts)
            ctx["complex"]["strategies"] = strategies
            summaries = [
                {
                    "name": s.get("name", f"strategy {idx+1}"),
                    "theme": s.get("theme"),
                    "summary": s.get("summary") or s.get("rationale", ""),
                }
                for idx, s in enumerate(strategies)
            ]
            polaris_log(
                ctx,
                "assistant",
                f"æœ€é©ã¨æ€ã‚ã‚Œã‚‹è¤‡æ•°æ¡ˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼ˆ{len(strategies)}ä»¶ï¼‰ã€‚æ¨ªä¸¦ã³ã§æ¯”è¼ƒã—ã¤ã¤æ‰¹åˆ¤çš„æ¤œè¨ã«é€²ã¿ã¾ã™ã€‚",
                payload={"kind": "strategies", "label": "ç”Ÿæˆã•ã‚ŒãŸæ”¿ç­–æ¡ˆã‚µãƒãƒª", "data": summaries},
            )
            pf["stage"] = "critique_run"
            continue
        if stage == "critique_run":
            strategies = ctx["complex"].get("strategies") or []
            if not strategies:
                pf["stage"] = "strategy_run"
                continue
            with st.spinner("æ‰¹åˆ¤çš„æ¤œè¨ï¼ˆä½•ãŒçŠ ç‰²ã«ãªã‚‹ã‹ï¼‰ã‚’å®Ÿè¡Œä¸­â€¦"):
                if _HAS_OPENAI and (OPENAI_API_KEY or "").strip():
                    critique = critique_strategies(strategies)
                else:
                    critique = local_critique(strategies)
            ctx["complex"]["critique"] = critique
            polaris_log(ctx, "assistant", "æ‰¹åˆ¤çš„æ¤œè¨ã‚’å®Œäº†ã—ã¾ã—ãŸã€‚æ¬¡ã«åˆ¶ç´„ä¸‹ã§ã®è³‡æºé…åˆ†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã™ã€‚")
            pf["stage"] = "simulation_run"
            continue
        if stage == "simulation_run":
            options = ctx["complex"].get("policy_options") or []
            if not options:
                pf["stage"] = "risk_run"
                continue
            scenario_cfgs = ctx["complex"].get("scenario_configs") or SCENARIO_TEMPLATES
            ctx["complex"]["scenario_configs"] = scenario_cfgs
            scenario_results = ctx["complex"].setdefault("scenario_results", {})
            years = ctx.get("years", list(range(2025, 2031)))
            options_df = pd.DataFrame(options)
            if options_df.empty:
                pf["stage"] = "risk_run"
                continue
            last_allocation = pd.DataFrame()
            with st.spinner("åˆ¶ç´„ä¸‹ã§ã®è³‡æºé…åˆ†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™â€¦"):
                for scenario in scenario_cfgs[:2]:
                    selected = optimize_scenario_allocation(
                        options_df,
                        scenario.get("budget", 0.0),
                        scenario.get("staff_limit", 0.0),
                    )
                    last_allocation = selected
                    result = simulate_scenario(years, scenario, selected)
                    scenario_results[scenario["name"]] = result
            ctx["complex"]["scenario_results"] = scenario_results
            if isinstance(last_allocation, pd.DataFrame) and not last_allocation.empty:
                ctx["picked"] = last_allocation
            polaris_log(ctx, "assistant", f"{len(scenario_results)} ã‚·ãƒŠãƒªã‚ªã§è³‡æºé…åˆ†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚ç¶šã„ã¦åŠ¹æœã¨ãƒªã‚¹ã‚¯ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚")
            pf["stage"] = "risk_run"
            continue
        if stage == "risk_run":
            if not ctx["complex"].get("risk_register"):
                ctx["complex"]["risk_register"] = RISK_SAMPLE
            exposure = calc_risk_exposure(ctx["complex"]["risk_register"], ctx.get("picked"))
            ctx["complex"]["risk_exposure"] = exposure.to_dict("records") if not exposure.empty else []
            payload = None
            if not exposure.empty:
                payload = {"kind": "table", "label": "ãƒªã‚¹ã‚¯æ„Ÿåº¦åˆ†æ", "data": exposure.to_dict("records")}
            polaris_log(ctx, "assistant", "ãã®æ¡ˆã®åŠ¹æœãƒ»ãƒªã‚¹ã‚¯ã‚’æ•´ç†ã—ã¾ã—ãŸã€‚RSã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰éå»äºˆç®—ã‚’æ¢ç´¢ã—ã€æ®µéšåˆ¥ã«å¯è¦–åŒ–ã—ã¾ã™â€¦", payload=payload)
            pf["stage"] = "budget_run"
            continue
        if stage == "budget_run":
            strategies = ctx["complex"].get("strategies") or []
            if not strategies:
                pf["stage"] = "done"
                continue
            with st.spinner("RSã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­â€¦äºˆç®—æƒ…å ±ã‚’æ¨å®šã—ã¦ã„ã¾ã™"):
                budgets = estimate_budgets(strategies)
            ctx["complex"]["budgets"] = budgets
            polaris_log(ctx, "assistant", "RSã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰éå»äºˆç®—ã‚’æ¢ç´¢ã—ã€æ®µéšåˆ¥ã«å¯è¦–åŒ–ã—ã¾ã—ãŸã€‚POLARIS ãƒ•ãƒ­ãƒ¼ã¯å®Œäº†ã§ã™ã€‚")
            pf["stage"] = "done"
            continue
        break


def handle_special_actions(prompt: str, ctx: Dict[str, Any]) -> List[str]:
    outputs: List[str] = []
    for conf in SPECIAL_ACTION_DEFS:
        if any(keyword in prompt for keyword in conf["keywords"]):
            if conf["name"] == "stakeholder":
                template = build_stakeholder_template(ctx)
                ctx.setdefault("stakeholder_templates", []).append({"time": now_str(), "template": template})
                outputs.append("ğŸ“¨ é–¢ä¿‚è€…ã‚¢ãƒ—ãƒ­ãƒ¼ãƒæ¡ˆ:\n\n" + template)
            else:
                outputs.append(conf.get("message") or "è¿½åŠ æ©Ÿèƒ½ã®æº–å‚™ä¸­ã§ã™ã€‚")
    return outputs
# --------------------
# OpenAI ãƒ©ãƒƒãƒ‘
# --------------------
def get_openai_client():
    key = OPENAI_API_KEY or os.getenv("OPENAI_API_KEY", "")
    if not (_HAS_OPENAI and key): return None
    if _CLIENT_KIND == "v1":
        return OpenAI(api_key=key)
    else:
        import openai as _legacy
        _legacy.api_key = key
        return "legacy"

def llm_chat(messages: List[dict], model: str = "gpt-4o") -> str:
    client = get_openai_client()
    if client is None:
        return "âš ï¸ OpenAI API Key ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã§ãã¾ã›ã‚“ã€‚.env ã« OPENAI_API_KEY=... ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
    try:
        if _CLIENT_KIND == "v1":
            resp = client.chat.completions.create(model=model, messages=messages, temperature=0.2, max_tokens=600)
            return resp.choices[0].message.content.strip()
        else:
            import openai as _legacy
            resp = _legacy.ChatCompletion.create(model=model, messages=messages, temperature=0.2, max_tokens=600)
            return resp.choices[0].message["content"].strip()
    except Exception as e:
        err = str(e)
        if any(x in err for x in ["401","403","Unauthorized","Authentication","invalid_api_key","api_key"]):
            return "âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        if any(x in err for x in ["404","model_not_found","No such model","is not permitted"]):
            return "âŒ ãƒ¢ãƒ‡ãƒ«æœªå¯¾å¿œ/å­˜åœ¨ã—ã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«åã‚’ 'gpt-4o-mini' ç­‰ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚"
        return f"âŒ LLMå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {err}"

# --------------------
# Tavily ç°¡æ˜“æ¤œç´¢ï¼ˆæ—¢å­˜ï¼‰
# --------------------
def web_search_tavily(query: str, max_results: int = 5) -> List[dict]:
    key = TAVILY_API_KEY or os.getenv("TAVILY_API_KEY", "")
    if not key: return []
    try:
        r = requests.post("https://api.tavily.com/search", json={
            "api_key": key, "query": query, "max_results": max_results,
            "include_answer": False, "include_raw_content": False, "search_depth": "basic",
        }, timeout=30)
        data = r.json()
        return data.get("results", [])
    except Exception as e:
        return [{"title":"æ¤œç´¢ã‚¨ãƒ©ãƒ¼","url":"","content":str(e)}]

def summarize_with_citations(question: str, results: List[dict]) -> str:
    if not results: return "ï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¤œç´¢ãŒç„¡åŠ¹ã€ã¾ãŸã¯çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰"
    snippets, links = [], []
    for i, r in enumerate(results[:5], start=1):
        title = shorten(r.get("title",""), 80); content = shorten(r.get("content",""), 400); url = r.get("url","")
        snippets.append(f"[{i}] {title}\n{content}"); links.append(f"[{i}] {title} â€” {url}")
    system = {"role":"system","content":"äº‹å®Ÿã¨æ¨æ¸¬ã‚’åˆ†ã‘ã€[1]å½¢å¼ã§æ ¹æ‹ ç•ªå·ã‚’ç¤ºã™ã€‚"}
    user = {"role":"user","content":f"è³ªå•: {question}\n\næŠœç²‹:\n" + "\n\n".join(snippets) + "\n\n3-6é …ç›®ã§è¦ç‚¹ã‚’æ›¸ãã€æœ€å¾Œã«å‚è€ƒãƒªãƒ³ã‚¯ã‚’åˆ—æŒ™ã€‚"}
    answer = llm_chat([system, user]); answer += "\n\nå‚è€ƒ:\n" + "\n".join(links)
    return answer

# --------------------
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# --------------------
with st.sidebar:
    st.header("Settings & Controls")
    st.caption("APIã‚­ãƒ¼ã¯ .env ã‹ã‚‰è‡ªå‹•èª­ã¿è¾¼ã¿")
    st.write(f".env: {_ENV_LOADED_FROM or 'ä¸æ˜'}")
    st.write(f"OpenAI: {'è¨­å®šæ¸ˆã¿' if (OPENAI_API_KEY or '').strip() else 'æœªè¨­å®š'}")
    st.write(f"Tavily: {'è¨­å®šæ¸ˆã¿' if (TAVILY_API_KEY or '').strip() else 'æœªè¨­å®š'}")
    st.session_state.use_web_search = st.checkbox("ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¤œç´¢ã‚’æœ‰åŠ¹åŒ–", value=st.session_state.use_web_search)
    st.session_state.restrict_rs = st.checkbox("RSã‚·ã‚¹ãƒ†ãƒ é™å®šï¼ˆæ”¿ç­–æ¤œç´¢ï¼‰", value=True)

    with st.expander("è¨ºæ–­ (Debug)"):
        st.write(f"HAS_OPENAI: {_HAS_OPENAI}")
        st.write(f"CLIENT_KIND: {_CLIENT_KIND}")
        st.write(f"HAS_AGENTS: {_HAS_AGENTS}")
        if not _HAS_AGENTS: st.write(f"AGENTS_IMPORT_ERR: {_AGENTS_IMPORT_ERR}")

    colA, colB = st.columns(2)
    with colA:
        if st.button("ğŸ†• æ–°ã—ã„ä¼šè©±"):
            start_new_conversation(); st.rerun()
    with colB:
        if st.button("ğŸ§¹ ã‚¯ãƒªã‚¢"):
            st.session_state.messages=[]; _init_state(); st.rerun()

    st.markdown("---")
    st.session_state.show_agent_blocks = st.checkbox("ğŸ” ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœè¡¨ç¤º", value=st.session_state.show_agent_blocks)

    if st.button("â–¶ï¸ ç›´è¿‘ã®ãƒ¦ãƒ¼ã‚¶å…¥åŠ›ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œ"):
        last_user = next((m.get("content") for m in reversed(st.session_state.messages) if m.get("role")=="user"), None)
        if last_user:
            with st.spinner("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œä¸­â€¦"):
                agents_out = {"error":"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæœªãƒ­ãƒ¼ãƒ‰"}
                if _HAS_AGENTS:
                    agents_out = run_ebpm_agents(
                        last_user,
                        prefer_rs_system=st.session_state.restrict_rs,       # â˜… è¿½åŠ 
                        force_policy_keyword="æ”¿ç­–",                          # â˜… è¿½åŠ 
                    )
            st.session_state.context["agents"] = agents_out
            log_message("assistant", "ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œå®Œäº†ï¼‰ã‚µã‚¤ãƒ‰ã®ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœè¡¨ç¤ºã€ã‚’ONã§ç¢ºèªã§ãã¾ã™ã€‚")
            st.rerun()
        else:
            st.warning("ãƒ¦ãƒ¼ã‚¶å…¥åŠ›ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚Chatã‚¿ãƒ–ã§èª²é¡Œã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")


    st.markdown("---")
    export_payload = {
        "current_session_id": st.session_state.current_session_id,
        "messages": st.session_state.messages,
        "context": st.session_state.context,
        "sessions": st.session_state.sessions,
        "exported_at": now_str(),
        "app_version": "chat-ebpm-demo-logs-2.0-research",
    }
    st.download_button("â¬‡ï¸ å…¨ãƒ­ã‚°JSONã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", data=json.dumps(export_payload, ensure_ascii=False, indent=2),
                       file_name=f"ebpm_chat_logs_{int(time.time())}.json", mime="application/json")
    st.write("ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆJSONï¼‰")
    up = st.file_uploader("é¸æŠ", type=["json"], key="import_json")
    if up:
        try:
            data = json.load(up)
            st.session_state.current_session_id = data.get("current_session_id", str(uuid.uuid4()))
            st.session_state.messages = [normalize_message(m) for m in data.get("messages", [])]
            st.session_state.context  = data.get("context", st.session_state.context)
            st.session_state.sessions = data.get("sessions", [])
            st.success("èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        except Exception as e:
            st.error(f"èª­ã¿è¾¼ã¿å¤±æ•—: {e}")

    st.markdown("---")
    feedback_text = st.text_area("å³æ™‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯", key="sidebar_feedback")
    if st.button("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é€ä¿¡", key="btn_sidebar_feedback"):
        if feedback_text.strip():
            st.session_state.context.setdefault("feedback_log", []).append({"time": now_str(), "text": feedback_text.strip()})
            st.success("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
        else:
            st.warning("å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    if st.session_state.context.get("feedback_log"):
        latest_fb = st.session_state.context["feedback_log"][-1]
        st.caption(f"æœ€æ–°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ ({latest_fb['time']}): {latest_fb['text']}")

# --------------------
# ã‚¿ãƒ–
# --------------------
tabs = st.tabs(["ğŸ’¬ Chat", "ğŸŒŸ POLARIS", "ğŸ“„ æ–‡æ›¸æŠ½å‡º", "ğŸ“ˆ æ™‚ç³»åˆ—/å› æœ", "ğŸ§¾ ç¾åœ¨ã®ä¼šè©±ãƒ­ã‚°", "ğŸ—‚ ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´", "â„¹ï¸ ä½¿ã„æ–¹"])
tab_chat, tab_orch, tab_docs, tab_ts, tab_current, tab_sessions, tab_help = tabs

# ===== Chat =====
with tab_chat:
    st.title("è¡Œæ”¿EBPMæ”¯æ´ãƒ„ãƒ¼ãƒ«ï¼ˆå¯¾è©±å‹ + ç ”ç©¶æ©Ÿèƒ½ï¼‰")
    st.caption("KPIâ†’æ–½ç­–æ¯”è¼ƒâ†’é…åˆ†â†’åŠ¹æœãƒ¬ãƒ³ã‚¸â†’ãƒ­ã‚¸ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«â†’ãƒ¢ãƒ‹ã‚¿ + LLMä¼šè©± + ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¤œç´¢ + ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç¾¤ + PDFæŠ½å‡º/å› æœåˆ†æ")
    render_stage_guide(st.session_state.context)
    with st.expander("âœï¸ æ”¿ç­–æ‹…å½“è€…ãƒ¡ãƒ¢", expanded=False):
        stage = st.session_state.context.get("policy_stage", "å•é¡Œæ„è­˜")
        current_note = st.session_state.context.get("stage_notes", {}).get(stage, "")
        memo = st.text_area(f"{stage} ã‚¹ãƒ†ãƒ¼ã‚¸ã®ãƒ¡ãƒ¢", value=current_note, key=f"stage_note_box_{stage}")
        if st.button("ã“ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã®ãƒ¡ãƒ¢ã‚’ä¿å­˜", key=f"save_stage_note_{stage}"):
            st.session_state.context.setdefault("stage_notes", {})[stage] = memo
            st.success("ãƒ¡ãƒ¢ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

    if len(st.session_state.messages)==0:
        log_message("assistant", "æ”¿ç­–èª²é¡Œã‚’æ•™ãˆã¦ãã ã•ã„ï¼ˆä¾‹: åœ°åŸŸåŒ»ç™‚ã®æ•‘æ€¥å—å…¥ç‡ã‚’æ”¹å–„ã—ãŸã„ï¼‰ã€‚ç›®æ¨™ã‚„äºˆç®—ãŒã‚ã‚Œã°ä¸€ç·’ã«ã€‚")

    for m in st.session_state.messages:
        with st.chat_message(m["role"]): st.markdown(m["content"])

    prompt = st.chat_input("å…¥åŠ›â€¦ï¼ˆ/web ã€œ ã§æ¤œç´¢, /agent ã€œ ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œï¼‰")
    if prompt:
        log_message("user", prompt)
        with st.chat_message("user"):
            st.markdown(prompt)
        ctx=st.session_state.context; responded=False

        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒˆãƒªã‚¬
        agent_triggered=False
        if prompt.strip().startswith("/agent") or "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ" in prompt:
            agent_query = prompt.replace("/agent","").strip() or prompt; agent_triggered=True
        elif st.session_state.show_agent_blocks and any(k in prompt for k in ["æ”¿ç­–","è«–æ–‡","KPI","ãƒ¬ãƒ“ãƒ¥ãƒ¼","å› æœ","ã‚°ãƒ©ãƒ•"]):
            agent_query = prompt; agent_triggered=True
        else:
            agent_query = prompt

        if agent_triggered and _HAS_AGENTS:
            with st.chat_message("assistant"):
                st.markdown(f"ğŸ§  ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œ: **{agent_query}**")
                with st.spinner("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç¾¤ã‚’èµ°ã‚‰ã›ã¦ã„ã¾ã™â€¦"):
                    agents_out = run_ebpm_agents(
                        agent_query,
                        prefer_rs_system=st.session_state.restrict_rs,   # â˜… è¿½åŠ 
                        force_policy_keyword="æ”¿ç­–",                      # â˜… è¿½åŠ 
                    )
            st.session_state.context["agents"] = agents_out
            k_n=len(agents_out.get("kpis_all", [])); p_n=len((agents_out.get("policy_search",{}) or {}).get("results",[])); a_n=len((agents_out.get("paper_search",{}) or {}).get("results",[]))
            msg_ag=f"âœ… ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœ: æ”¿ç­– {p_n} / è«–æ–‡ {a_n} / KPI {k_n}ï¼ˆã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœè¡¨ç¤ºã€ã§è©³ç´°ï¼‰ã€‚"
            log_message("assistant", msg_ag)
            with st.chat_message("assistant"):
                st.success(msg_ag)

        # æ—¢å­˜æ„å›³æ¤œå‡º
        if any(k in prompt for k in ["åŒ»ç™‚","æ•‘æ€¥","åŒ»å¸«","åœ°åŸŸåŒ»ç™‚"]):
            ctx["domain"]="åœ°åŸŸåŒ»ç™‚"; kpis=KPI_CATALOG["åœ°åŸŸåŒ»ç™‚"]
            msg=f"**KPIå€™è£œ**: {', '.join(kpis)}\n\nç›®æ¨™ã—ãã„å€¤ï¼ˆä¾‹: *æ•‘æ€¥å—å…¥ç‡ 80%*ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
            log_message("assistant", msg)
            with st.chat_message("assistant"):
                st.markdown(msg)
            responded=True
        m_thr = re.search(r"(?:ç›®æ¨™|ã—ãã„å€¤|threshold).{0,6}?(\d{2,3})\s*[%ï¼…]?", prompt)
        if m_thr:
            ctx["thr"]=float(m_thr.group(1)); msg=f"ç›®æ¨™ã—ãã„å€¤ã‚’ **{m_thr.group(1)}** ã«è¨­å®šã€‚KPIåã‚‚æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
            log_message("assistant", msg)
            with st.chat_message("assistant"):
                st.markdown(msg)
            responded=True
        m_kpi = re.search(r"(æ•‘æ€¥å—å…¥ç‡|åŒ»å¸«1äººã‚ãŸã‚Šæ‚£è€…æ•°|åˆè¨ºå¾…æ©Ÿæ—¥æ•°)", prompt)
        if m_kpi:
            kpi_name = m_kpi.group(1)
            set_kpi_targets(ctx, [kpi_name])
            msg=f"KPIã‚’ **{kpi_name}** ã«è¨­å®šã€‚äºˆç®—é¡ï¼ˆå„„å††ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
            log_message("assistant", msg)
            with st.chat_message("assistant"):
                st.markdown(msg)
            responded=True
        m_budget = re.search(r"(\d+(?:\.\d+)?)\s*å„„", prompt)
        if m_budget:
            ctx["budget"]=float(m_budget.group(1)); pessim, optim = 0.2, 0.2
            df = pd.DataFrame([{"æ–½ç­–": n, "ã‚³ã‚¹ãƒˆ(å„„å††)": info["cost"], "åŠ¹æœ(ä¸­ä½)": info["effect"],
                                "åŠ¹æœ(æ‚²è¦³)": round(info["effect"]*(1-pessim),1), "åŠ¹æœ(æ¥½è¦³)": round(info["effect"]*(1+optim),1),
                                "ãƒ©ã‚°(å¹´)": info["lag"], "ãƒªã‚¹ã‚¯": info["risk"]} for n,info in POLICY_LIBRARY.items()])
            ctx["candidates"]=df
            msg=f"äºˆç®— **{m_budget.group(1)}å„„å††** ã§å€™è£œæ–½ç­–ã‚’æç¤ºã€‚"; log_message("assistant", msg);
            with st.chat_message("assistant"):
                st.markdown(msg)
                st.plotly_chart(bubble_chart(df), use_container_width=True)
                st.caption("å‰æ: ã‚³ã‚¹ãƒˆ/åŠ¹æœã¯ä»®ã®ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯å€¤ã§ã™ã€‚ç·¨é›†ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§èª¿æ•´ã§ãã¾ã™ã€‚")
            responded=True
        if any(k in prompt for k in ["æ¡æŠ","é…åˆ†","æœ€é©","é¸ã‚“ã§","æ±ºã‚ã¦"]):
            picked, cost_sum, eff_sum = greedy_allocation(ctx.get("candidates"), ctx.get("budget") or 0.0)
            ctx["picked"]=picked; msg=f"**æ¡æŠçµæœ**ï¼ˆè²ªæ¬²æ³•ï¼‰\n- ã‚³ã‚¹ãƒˆåˆè¨ˆ: **{cost_sum:.1f}å„„å††**\n- åŠ¹æœ(ä¸­ä½)åˆè¨ˆ: **{eff_sum:.1f}**"
            log_message("assistant", msg, {"picked_count": int(len(picked))})
            with st.chat_message("assistant"): st.markdown(msg); st.dataframe(picked, use_container_width=True); responded=True
        if any(k in prompt for k in ["å°†æ¥","æ¨ç§»","ãƒ¬ãƒ³ã‚¸","åŠ¹æœ","ã‚·ãƒŠãƒªã‚ª","ã‚°ãƒ©ãƒ•","å¯è¦–åŒ–"]):
            years=ctx["years"]; base_start=ctx["base_start"]; drift=ctx["drift"]; thr=ctx["thr"]; kpi=get_primary_kpi_name(ctx) or "KPI"
            picked=ctx["picked"] or pd.DataFrame(columns=["åŠ¹æœ(ä¸­ä½)","åŠ¹æœ(æ‚²è¦³)","åŠ¹æœ(æ¥½è¦³)","ãƒ©ã‚°(å¹´)"])
            lag_profile={0:0.0,1:0.5,2:0.8,3:1.0}
            pol_mid =[{"effect":r["åŠ¹æœ(ä¸­ä½)"],"lag":int(r["ãƒ©ã‚°(å¹´)"])} for _,r in picked.iterrows()]
            pol_low =[{"effect":r["åŠ¹æœ(æ‚²è¦³)"],"lag":int(r["ãƒ©ã‚°(å¹´)"])} for _,r in picked.iterrows()]
            pol_high=[{"effect":r["åŠ¹æœ(æ¥½è¦³)"],"lag":int(r["ãƒ©ã‚°(å¹´)"])} for _,r in picked.iterrows()]
            base = simulate_kpi(years, base_start, drift, [], lag_profile)
            mid  = simulate_kpi(years, base_start, drift, pol_mid, lag_profile)
            low  = simulate_kpi(years, base_start, drift, pol_low, lag_profile)
            high = simulate_kpi(years, base_start, drift, pol_high, lag_profile)
            primary_constraint = None
            for c in ctx.get("kpi_constraints", []) or []:
                if c.get("name") == kpi:
                    primary_constraint = c
                    break
            threshold_lines = None
            if primary_constraint:
                thr_value = _to_float(primary_constraint.get("threshold_hint"))
                if thr_value is not None:
                    label_prefix = "â‰§" if (primary_constraint.get("threshold_type") or "min") == "min" else "â‰¦"
                    unit = primary_constraint.get("unit") or ""
                    threshold_lines = [{"value": thr_value, "label": f"{kpi} {label_prefix} {thr_value}{unit}"}]
                    thr_display = None
                else:
                    thr_display = thr
            else:
                thr_display = thr
            if not primary_constraint:
                primary_constraint = None
            alerts = threshold_breaches(years, low, high, primary_constraint) if primary_constraint else []
            msg = "**KPIäºˆæ¸¬ãƒ¬ãƒ³ã‚¸**ã¨**ãƒ­ã‚¸ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«**ã‚’è¡¨ç¤ºã€‚"; log_message("assistant", msg)
            with st.chat_message("assistant"):
                st.markdown(msg)
                st.plotly_chart(band_chart(years, mid, low, high, thr_display, kpi, threshold_lines), use_container_width=True)
                st.caption("å‰æ: åŠ¹æœå€¤ã¯é¸æŠæ–½ç­–ã®ä»®å®šå€¤ã‚’åˆç®—ã€‚é–¾å€¤ç·šã‚’ä¸‹å›ã‚‹ã¨è­¦å‘ŠãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
                if alerts:
                    for al in alerts:
                        st.warning(al)
                st.plotly_chart(logic_model_figure(), use_container_width=True)
                responded=True
        if any(k in prompt for k in ["å®Ÿç¸¾","CSV","é‡ã­","ãƒ¬ãƒ“ãƒ¥ãƒ¼","ãƒ¢ãƒ‹ã‚¿"]):
            msg = "CSVï¼ˆåˆ—: `Year,Value`ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"; log_message("assistant", msg)
            with st.chat_message("assistant"): st.markdown(msg)
            uploaded=st.file_uploader("å®Ÿç¸¾CSV", type=["csv"], key=f"real_csv_{uuid.uuid4()}")
            if uploaded:
                df_real=pd.read_csv(uploaded)
                if {"Year","Value"}.issubset(df_real.columns):
                    years=ctx["years"]; kpi=get_primary_kpi_name(ctx) or "KPI"; thr=ctx["thr"]; picked=ctx["picked"] or pd.DataFrame(columns=["åŠ¹æœ(ä¸­ä½)","ãƒ©ã‚°(å¹´)"])
                    lag_profile={0:0.0,1:0.5,2:0.8,3:1.0}
                    pol_mid=[{"effect":r["åŠ¹æœ(ä¸­ä½)"],"lag":int(r["ãƒ©ã‚°(å¹´)"])} for _,r in picked.iterrows()]
                    mid=simulate_kpi(years, ctx["base_start"], ctx["drift"], pol_mid, lag_profile)
                    merged_years=sorted(set(years).union(set(df_real["Year"].tolist())))
                    mid_series=pd.Series(mid, index=years).reindex(merged_years).interpolate()
                    fig=go.Figure(); fig.add_trace(go.Scatter(x=merged_years, y=mid_series, name="äºˆæ¸¬(ä¸­ä½)", mode="lines"))
                    fig.add_trace(go.Scatter(x=df_real["Year"], y=df_real["Value"], name="å®Ÿç¸¾", mode="lines+markers"))
                    threshold_lines = None
                    primary_constraint = None
                    for c in ctx.get("kpi_constraints", []) or []:
                        if c.get("name") == kpi:
                            primary_constraint = c
                            break
                    if primary_constraint:
                        thr_value = _to_float(primary_constraint.get("threshold_hint"))
                        if thr_value is not None:
                            label_prefix = "â‰§" if (primary_constraint.get("threshold_type") or "min") == "min" else "â‰¦"
                            unit = primary_constraint.get("unit") or ""
                            threshold_lines = [{"value": thr_value, "label": f"{kpi} {label_prefix} {thr_value}{unit}"}]
                    if threshold_lines:
                        for th in threshold_lines:
                            fig.add_hline(y=th["value"], line_dash="dash", annotation_text=th["label"])
                    elif thr is not None:
                        fig.add_hline(y=thr, line_dash="dash", annotation_text=f"Threshold={thr}")
                    with st.chat_message("assistant"): st.plotly_chart(fig, use_container_width=True)
                    latest=int(df_real["Year"].max()); pred=float(mid_series.loc[latest]); real=float(df_real.loc[df_real["Year"]==latest,"Value"].iloc[0]); diff=real-pred
                    msg2=f"æœ€æ–°å¹´ã®ä¹–é›¢ï¼ˆå®Ÿç¸¾-äºˆæ¸¬ï¼‰: **{diff:+.2f}**"
                    log_message("assistant", msg2)
                    with st.chat_message("assistant"):
                        st.markdown(msg2)
                else:
                    with st.chat_message("assistant"): st.error("åˆ—åãŒä¸æ­£ã§ã™ã€‚'Year','Value' ã‚’å«ã‚€CSVã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        special_msgs = handle_special_actions(prompt, ctx)
        for smsg in special_msgs:
            with st.chat_message("assistant"):
                st.markdown(smsg)
            responded = True
        web_cmd=None
        if prompt.strip().startswith("æ¤œç´¢:"): web_cmd = prompt.strip().split("æ¤œç´¢:",1)[1].strip()
        elif prompt.strip().startswith("/web"): web_cmd = prompt.strip().split("/web",1)[1].strip()
        elif st.session_state.use_web_search and any(k in prompt for k in ["èª¿ã¹ã¦","æ¤œç´¢","æœ€æ–°","äº‹ä¾‹","è«–æ–‡","ãƒ‡ãƒ¼ã‚¿"]):
            web_cmd = prompt
        if web_cmd:
            with st.chat_message("assistant"): st.markdown(f"ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¤œç´¢: **{web_cmd}** ã‚’å®Ÿè¡Œä¸­â€¦")
            results = web_search_tavily(web_cmd, max_results=5); summary = summarize_with_citations(web_cmd, results)
            log_message("assistant", summary)
            with st.chat_message("assistant"):
                st.markdown(summary)

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœè¡¨ç¤º
    agents = st.session_state.context.get("agents")
    if st.session_state.show_agent_blocks and agents:
        st.markdown("---"); st.subheader("ğŸ” ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœ")
        if "error" in agents: st.error(agents["error"])
        else:
            c1,c2,c3=st.columns(3)
            with c1:
                st.markdown("**æ”¿ç­–æ¤œç´¢**")
                pol=(agents.get("policy_search",{}) or {}).get("results",[])
                st.dataframe(pd.DataFrame(pol)[["rank","title","url"]].head(10) if pol else pd.DataFrame(), use_container_width=True)
            with c2:
                st.markdown("**è«–æ–‡æ¤œç´¢**")
                pap=(agents.get("paper_search",{}) or {}).get("results",[])
                df=pd.DataFrame(pap); cols=[c for c in ["rank","title","url","evidence","note"] if c in df.columns]
                st.dataframe(df[cols].head(10) if not df.empty else pd.DataFrame(), use_container_width=True)
            with c3:
                all_kpis=agents.get("kpis_all",[]); st.metric("KPIæ•°", len(all_kpis))
                if all_kpis:
                    st.write(", ".join(sorted({str(x.get("name","")) for x in all_kpis})[:30]))

# ===== æ–‡æ›¸æŠ½å‡º =====
with tab_docs:
    st.subheader("ğŸ“„ ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚·ãƒ¼ãƒˆæŠ½å‡ºï¼ˆPDF â†’ æ¦‚è¦ãƒ»å› æœãƒ‘ã‚¹ï¼‰")
    ctx = st.session_state.context
    c1, c2 = st.columns(2)
    with c1:
        rs_file = st.file_uploader("RSãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚·ãƒ¼ãƒˆè§£èª¬ãªã©ã®åŸºæº–PDFï¼‰", type=["pdf"], key="rs_pdf")
    with c2:
        target_pdf = st.file_uploader("å¯¾è±¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚·ãƒ¼ãƒˆï¼ˆã¾ãŸã¯æ”¿ç­–è³‡æ–™ï¼‰PDF", type=["pdf"], key="rs_target_pdf")

    colA, colB, colC = st.columns(3)
    with colA:
        if st.button("â‘  RSãƒ—ãƒªãƒç”Ÿæˆ"):
            if rs_file:
                tmp = Path(st.secrets.get("tmp_dir",".")) / f"rs_{uuid.uuid4().hex}.pdf"
                tmp.write_bytes(rs_file.read())
                with st.spinner("ãƒ—ãƒªãƒç”Ÿæˆâ€¦"):
                    primer = build_rs_primer(str(tmp)) if _HAS_AGENTS else None
                ctx["primer"] = primer; st.success("ç”Ÿæˆã—ã¾ã—ãŸ"); st.json(primer or {})
            else:
                st.warning("RSãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆPDFã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
    with colB:
        if st.button("â‘¡ ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚·ãƒ¼ãƒˆæŠ½å‡ºï¼ˆMap/Reduceï¼‰"):
            if target_pdf:
                tmp = Path(st.secrets.get("tmp_dir",".")) / f"doc_{uuid.uuid4().hex}.pdf"
                tmp.write_bytes(target_pdf.read())
                with st.spinner("æŠ½å‡ºä¸­â€¦"):
                    rs = extract_effect_pathway(str(tmp)) if _HAS_AGENTS else None
                ctx["rs_result"] = rs; st.success("æŠ½å‡ºã—ã¾ã—ãŸ"); st.json(rs or {})
            else:
                st.warning("å¯¾è±¡PDFã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

    st.markdown("---")
    st.subheader("ğŸ§ª KPIã‚·ãƒ¼ãƒ‰ï¼ˆæ–­ç‰‡â†’A/Båˆ†é¡ï¼‰ã¨ã‚³ãƒ¼ãƒ‘ã‚¹PDFã§ã®KPIå¢—è£œ")
    frag = st.text_area("KPIæ–­ç‰‡ï¼ˆè¤‡æ•°ã‚’æ”¹è¡Œã§ï¼‰", height=120, key="kpi_frag")
    add_pdf = st.file_uploader("KPIå¢—è£œç”¨ã®è¿½åŠ PDFï¼ˆè¤‡æ•°å¯ï¼‰", type=["pdf"], accept_multiple_files=True, key="kpi_add_pdfs")
    cA, cB = st.columns(2)
    with cA:
        if st.button("â‘¢ æ–­ç‰‡ã‹ã‚‰KPIã‚·ãƒ¼ãƒ‰ç”Ÿæˆ"):
            if frag.strip():
                fragments = [s for s in frag.split("\n") if s.strip()]
                with st.spinner("KPIã‚·ãƒ¼ãƒ‰æŠ½å‡ºâ€¦"):
                    seed = seed_kpis_from_fragments(fragments) if _HAS_AGENTS else None
                ctx["kpi_seed_fragments"]=fragments; ctx["kpi_catalog"]=seed
                st.success("æŠ½å‡ºã—ã¾ã—ãŸ"); st.json(seed or {})
            else:
                st.warning("æ–­ç‰‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    with cB:
        if st.button("â‘£ è¿½åŠ PDFã§KPIå¢—è£œ/ãƒãƒ¼ã‚¸"):
            if ctx.get("kpi_catalog") and add_pdf:
                paths=[]
                for f in add_pdf:
                    p = Path(st.secrets.get("tmp_dir",".")) / f"add_{uuid.uuid4().hex}.pdf"
                    p.write_bytes(f.read()); paths.append(str(p))
                with st.spinner("å¢—è£œä¸­â€¦"):
                    updated = update_kpis_with_pdfs(ctx["kpi_catalog"], paths) if _HAS_AGENTS else None
                ctx["kpi_catalog"]=updated; st.success("æ›´æ–°ã—ã¾ã—ãŸ"); st.json(updated or {})
            else:
                st.warning("KPIã‚·ãƒ¼ãƒ‰ç”Ÿæˆã¨è¿½åŠ PDFã®ä¸¡æ–¹ãŒå¿…è¦ã§ã™ã€‚")

# ===== æ™‚ç³»åˆ—/å› æœ =====
with tab_ts:
    st.subheader("ğŸ“ˆ æ™‚ç³»åˆ—åé›†ï¼ˆWebï¼‰â†’ ğŸ” å› æœæ¨å®šï¼ˆTE / VARâ€“Grangerï¼‰")
    ctx = st.session_state.context
    if st.button("â‘¤ åŠ¹æœç™ºç¾çµŒè·¯ï¼ˆã‚¨ãƒƒã‚¸ï¼‰ã‚’åé›†"):
        rs = ctx.get("rs_result") or {}
        models = [rs] if rs else []
        ctx["effect_models"]=models
        st.json({"edges": collect_edges(models)})
    kpi_names = []
    catalog_obj = ctx.get("kpi_catalog")
    if isinstance(catalog_obj, dict):
        kpi_names += [x.get("name", "") for x in catalog_obj.get("quantitative_kpi", [])]
        kpi_names += [x.get("name", "") for x in catalog_obj.get("hard_to_quantify_kpi", [])]
    elif isinstance(catalog_obj, list):
        kpi_names += [x.get("name", "") for x in catalog_obj if isinstance(x, dict)]
    kpi_names = sorted({n for n in kpi_names if n})
    st.write(f"KPIå€™è£œæ•°: {len(kpi_names)}")
    if st.button("â‘¥ KPIåãƒªã‚¹ãƒˆã‚’è¡¨ç¤º"):
        st.write(", ".join(kpi_names[:50]))

    labels_input = st.text_area("ãƒãƒ¼ãƒ‰ï¼ˆæŒ‡æ¨™ï¼‰åï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šã€ç©ºãªã‚‰è‡ªå‹•æ¨å®šä¸å¯ï¼‰", height=120, key="ts_labels")
    if st.button("â‘¦ æŒ‡æ¨™ã”ã¨ã«Webã‹ã‚‰æ™‚ç³»åˆ—ã‚’åé›†ï¼ˆæœ€å¤§10ç‚¹ï¼‰"):
        labels = [s.strip() for s in labels_input.split("\n") if s.strip()]
        if not labels:
            st.warning("ãƒãƒ¼ãƒ‰åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("åé›†ä¸­â€¦ã‚„ã‚„æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™"):
                per_node_ts = build_kpi_timeseries(labels) if _HAS_AGENTS else {}
            ctx["per_node_timeseries"]=per_node_ts
            for lab, ts in per_node_ts.items():
                st.write(f"**{lab}**"); st.dataframe(pd.DataFrame(ts), use_container_width=True)

    if st.button("â‘§ Transfer Entropy / VARâ€“Granger ã‚’å®Ÿè¡Œ"):
        models = ctx.get("effect_models") or []
        edges = collect_edges(models)
        ts = ctx.get("per_node_timeseries") or {}
        if not edges:
            st.warning("ã‚¨ãƒƒã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆæ–‡æ›¸æŠ½å‡ºâ†’â‘¤ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼‰ã€‚")
        elif not ts:
            st.warning("æ™‚ç³»åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆâ‘¦ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼‰ã€‚")
        else:
            with st.spinner("å› æœæ¨å®šâ€¦ï¼ˆæ•°åˆ†ã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ï¼‰"):
                res = run_causality(ts, edges) if _HAS_AGENTS else {}
            ctx["causality"]=res
            st.success("å®Œäº†")
            st.subheader("Transfer Entropy")
            st.dataframe(pd.json_normalize(res.get("transfer_entropy", [])), use_container_width=True)
            st.subheader("VARâ€“Granger")
            st.dataframe(pd.DataFrame(res.get("granger", [])), use_container_width=True)

# ===== ç¾åœ¨ã®ä¼šè©±ãƒ­ã‚° =====
with tab_current:
    st.subheader("ç¾åœ¨ã®ä¼šè©±ãƒ­ã‚°")
    if st.session_state.messages:
        safe = [normalize_message(m) for m in st.session_state.messages]
        df_log = pd.DataFrame(safe)[["t","role","content"]]
        df_log["content_preview"] = df_log["content"].apply(lambda s: (s.replace("\n"," ")[:200]+"â€¦") if len(s)>200 else s)
        st.dataframe(df_log, use_container_width=True); st.caption("å…¨æ–‡ã¯ Chat ã‚¿ãƒ–ã§ç¢ºèªã€‚Export ã§JSONä¿å­˜å¯ã€‚")
    else:
        st.info("ã¾ã ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# ===== ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ =====
with tab_sessions:
    st.subheader("ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´")
    if st.session_state.sessions:
        for i, ses in enumerate(reversed(st.session_state.sessions), start=1):
            with st.expander(f"[{i}] {ses['started_at']} - {ses['ended_at']}  / msgs={len(ses['messages'])}"):
                ctx = ses.get("context", {})
                kpi_labels = ", ".join(get_kpi_targets(ctx) or ([ctx.get('kpi')] if ctx.get('kpi') else [])) or "æœªè¨­å®š"
                st.write(f"- domain: {ctx.get('domain')}, kpi: {kpi_labels}, thr: {ctx.get('thr')}, budget: {ctx.get('budget')}")
                st.write(f"- agents: {'ã‚ã‚Š' if ctx.get('agents') else 'ãªã—'} / RSæŠ½å‡º: {'ã‚ã‚Š' if ctx.get('rs_result') else 'ãªã—'} / KPIã‚«ã‚¿ãƒ­ã‚°: {'ã‚ã‚Š' if ctx.get('kpi_catalog') else 'ãªã—'}")
                for m in ses["messages"]:
                    mm = normalize_message(m); st.markdown(f"**{mm['t']} [{mm['role']}]**  \n{mm['content']}")
                if st.button("ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å¾©å…ƒ", key=f"restore_{ses['id']}"):
                    st.session_state.current_session_id = ses["id"]
                    st.session_state.messages = [normalize_message(m) for m in ses["messages"]]
                    st.session_state.context  = ses.get("context", st.session_state.context)
                    st.rerun()
    else:
        st.info("ä¿å­˜æ¸ˆã¿ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

# ===== ä½¿ã„æ–¹ =====
with tab_help:
    st.subheader("ä½¿ã„æ–¹ï¼ˆè¦ç‚¹ï¼‰")
    st.markdown("""
- **æ™®é€šã«è©±ã™** â†’ OpenAIã§å¿œç­”ï¼ˆAPI Keyè¦ï¼‰ã€‚
- **ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¤œç´¢** â†’ `æ¤œç´¢: ...` or `/web ...`ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¤œç´¢ã‚’æœ‰åŠ¹åŒ–ã€ã€‚
- **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ** â†’ `/agent ...` ã¾ãŸã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®å®Ÿè¡Œãƒœã‚¿ãƒ³ã€‚
- **ğŸ“„ æ–‡æ›¸æŠ½å‡º** â†’ RSåŸºæº–PDFâ†’ãƒ—ãƒªãƒç”Ÿæˆâ†’å¯¾è±¡PDFã‹ã‚‰ æ¦‚è¦/å› æœãƒ‘ã‚¹ï¼ˆMap/Reduceï¼‰ã€‚
- **KPI** â†’ æ–­ç‰‡ã‹ã‚‰A/Båˆ†é¡ã§ã‚·ãƒ¼ãƒ‰â†’è¿½åŠ PDFã§å¢—è£œ/ãƒãƒ¼ã‚¸ã€‚
- **ğŸ“ˆ æ™‚ç³»åˆ—/å› æœ** â†’ ãƒãƒ¼ãƒ‰åã‚’å…¥åŠ›â†’Webã‹ã‚‰æœ€å¤§10ç‚¹æŠ½å‡ºâ†’TE/VARâ€“Grangerã€‚
""")

with tab_orch:
    col_logo, col_title = st.columns([1, 2])
    with col_logo:
        logo_path = Path("static/polaris_logo.png")
        if logo_path.exists():
            st.image(str(logo_path), use_column_width=True)
        else:
            st.info("static/polaris_logo.png ã‚’é…ç½®ã™ã‚‹ã¨ POLARIS ãƒ­ã‚´ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    with col_title:
        st.title("ğŸŒŸ POLARIS")
        st.markdown("**Policy Optimization through Linked Analysis of Reliable Indicators & Statistics**")
        st.caption("è©³ç´°åŒ– â†’ æ¤œç´¢ â†’ è¤‡æ•°æ¡ˆ â†’ æ‰¹åˆ¤ â†’ äºˆç®—å¯è¦–åŒ–")
    ctx = st.session_state.context
    if "complex" not in ctx:
        ctx["complex"] = {
            "refined": None,
            "confirmed": False,
            "workplan": None,
            "topic_map": None,
            "topic_layer_hits": None,
            "policy_hypotheses": None,
            "kpi_templates": [],
            "kpi_constraints": [],
            "search_results": None,
            "strategies": [],
            "critique": None,
            "budgets": [],
            "user_query": None,
            "qual_entries": [],
            "hypothesis_clusters": [],
            "policy_options": [],
            "scenario_configs": [],
            "scenario_results": {},
            "risk_register": [],
            "evidence_gaps": [],
            "contention_points": [],
            "hypothesis_gap_analysis": [],
            "agent_competition": {},
            "decision_notes": "",
        }

    # --- Step 1: POLARISãƒãƒ£ãƒƒãƒˆãƒ•ãƒ­ãƒ¼ ---
    st.subheader("1) æ”¿ç­–èª²é¡Œã®è©³ç´°åŒ–ï¼ˆPOLARISãƒãƒ£ãƒƒãƒˆï¼‰")
    if st.button("POLARISãƒ•ãƒ­ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ", key="btn_reset_polaris_flow"):
        ctx.pop("polaris_flow", None)
        ctx["complex"].update({
            "refined": None,
            "confirmed": False,
            "workplan": None,
            "topic_map": None,
            "topic_layer_hits": None,
            "policy_hypotheses": None,
            "kpi_templates": [],
            "kpi_constraints": [],
            "search_results": None,
            "strategies": [],
            "critique": None,
            "budgets": [],
            "user_query": None,
            "qual_entries": [],
            "hypothesis_clusters": [],
            "policy_options": [],
            "scenario_configs": [],
            "scenario_results": {},
            "risk_register": [],
            "evidence_gaps": [],
            "contention_points": [],
            "hypothesis_gap_analysis": [],
            "agent_competition": {},
            "decision_notes": "",
        })
        st.rerun()
    pf = get_polaris_flow(ctx)
    if not pf["messages"]:
        polaris_log(ctx, "assistant", "POLARISã§ã™ã€‚æ”¿ç­–èª²é¡Œã«ã¤ã„ã¦è«–ã˜ã¦ãã ã•ã„ã€‚èƒŒæ™¯ãƒ»ç¾çŠ¶ãƒ»æ°—ã«ãªã£ã¦ã„ã‚‹æŒ‡æ¨™ãªã©ã‚’è‡ªç”±ã«ã©ã†ãã€‚")
    advance_polaris_flow(ctx)
    render_polaris_chat(ctx)
    stage = pf.get("stage", "ask_problem")
    if stage == "ask_problem":
        user_reply = st.chat_input("æ”¿ç­–èª²é¡Œã«ã¤ã„ã¦è«–ã˜ã¦ãã ã•ã„", key="polaris_problem_input")
        if user_reply:
            pf["problem"] = user_reply
            ctx["complex"]["user_query"] = user_reply
            polaris_log(ctx, "user", user_reply)
            polaris_log(ctx, "assistant", "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚è©³ç´°åŒ–ï¼ˆStep1ï¼‰ã«å–ã‚Šæ›ã‹ã‚Šã¾ã™ã€‚")
            pf["stage"] = "refine"
            st.rerun()
    elif stage == "kpi_confirm":
        st.info("ãƒ†ãƒ¼ãƒ–ãƒ«ã§KPIã¨åˆ¶ç´„æ¡ä»¶ã‚’èª¿æ•´å¾Œã€ã€KPIè¨­å®šå®Œäº†ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
        if st.button("KPIè¨­å®šå®Œäº†", key="btn_polaris_kpi_done"):
            polaris_log(ctx, "assistant", "è³ªçš„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŸå› ä»®èª¬ã‚’ç”Ÿæˆãƒ»æ•´ç†ã—ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            pf["stage"] = "qual_prompt"
            st.rerun()
    elif stage == "qual_prompt":
        st.info("è³ªçš„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŸå› ä»®èª¬ã‚’ç”Ÿæˆãƒ»æ•´ç†ã—ã¾ã™ã€‚txt/csv/mdãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
        qual_files = st.file_uploader("è³ªçš„ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡æ•°å¯ï¼‰", type=["txt", "csv", "md"], accept_multiple_files=True, key="polaris_qual_files")
        col_q1, col_q2 = st.columns(2)
        with col_q1:
            if st.button("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ", key="btn_polaris_qual_upload"):
                entries = load_qualitative_entries(qual_files)
                if not entries:
                    st.warning("ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                else:
                    pf["qual_entries"] = entries
                    polaris_log(ctx, "assistant", "å…¥åŠ›ã—ã¾ã—ãŸã€‚è³ªçš„ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã¾ã™ã€‚")
                    pf["stage"] = "qual_analyze"
                    st.rerun()
        with col_q2:
            if st.button("ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è§£æ", key="btn_polaris_qual_dummy"):
                pf["qual_entries"] = [dict(sample) for sample in QUAL_SAMPLE_TEXTS]
                polaris_log(ctx, "assistant", "å…¥åŠ›ã—ã¾ã—ãŸï¼ˆä»Šå›ã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼‰ã€‚è³ªçš„ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã¾ã™ã€‚")
                pf["stage"] = "qual_analyze"
                st.rerun()
    elif stage == "policy_confirm":
        st.info("ã“ã®æ–¹é‡ã§é€²ã‚ã¦ã‚ˆã‚ã—ã„ã§ã™ã‹ï¼Ÿ")
        choice = st.radio("POLARISã®ææ¡ˆæ–¹é‡ã«åŒæ„ã—ã¾ã™ã‹ï¼Ÿ", ["é¸æŠã—ã¦ãã ã•ã„", "ã¯ã„", "ã„ã„ãˆ"], index=0, key="polaris_policy_choice")
        if st.button("å›ç­”ã™ã‚‹", key="btn_polaris_policy_confirm"):
            if choice == "ã¯ã„":
                polaris_log(ctx, "assistant", "äº†è§£ã—ã¾ã—ãŸã€‚ã‚¿ã‚¹ã‚¯ã‚’åˆ†è§£ã•ã›ã€è‡ªå‹•ã§æ¤œç´¢â†’è¤‡æ•°æ¡ˆã®æ¯”è¼ƒã«é€²ã¿ã¾ã™ã€‚")
                pf["stage"] = "decompose_run"
                st.rerun()
            elif choice == "ã„ã„ãˆ":
                polaris_log(ctx, "assistant", "æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚è³ªçš„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å†åº¦æ•´ç†ã—ã¾ã™ã®ã§ã€å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                pf["stage"] = "qual_prompt"
                st.rerun()
            else:
                st.warning("ã€Œã¯ã„ã€ã¾ãŸã¯ã€Œã„ã„ãˆã€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    elif stage in {"decompose_run", "search_run", "strategy_run", "critique_run", "simulation_run", "risk_run", "budget_run"}:
        st.info("å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’è‡ªå‹•å®Ÿè¡Œä¸­ã§ã™ã€‚é€²è¡ŒçŠ¶æ³ã¯ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
    elif stage == "done":
        st.success("POLARIS ãƒ•ãƒ­ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚å¿…è¦ã«å¿œã˜ã¦ä¸‹éƒ¨ã®å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§è©³ç´°ã‚’ç·¨é›†ã—ã¦ãã ã•ã„ã€‚")

    if ctx["complex"].get("refined"):
        with st.expander("è©³ç´°åŒ–ã—ãŸå†…å®¹ï¼ˆJSONï¼‰", expanded=False):
            st.json(ctx["complex"]["refined"])

    # --- Step 1-b: KPIè¨­å®šã¨åˆ¶ç´„ ---
    st.markdown("### 1-b) KPIè¨­å®šã¨åˆ¶ç´„æ¡ä»¶ã®æ˜ç¢ºåŒ–")
    kpi_domain_hint = st.text_input("ä¸»ã¨ãªã‚‹æ”¿ç­–ãƒ‰ãƒ¡ã‚¤ãƒ³ (ä¾‹: åœ°åŸŸåŒ»ç™‚)", value=ctx.get("domain") or "", key="kpi_domain_hint")
    col_kpi1, col_kpi2 = st.columns([2,1])
    with col_kpi1:
        st.caption("èª²é¡Œã®æ–‡è„ˆã‹ã‚‰ KPI å€™è£œã¨æƒ³å®šé–¾å€¤ã‚’è‡ªå‹•ææ¡ˆã€‚é–¾å€¤ç¨®åˆ¥: min=æœ€ä½ä¿è¨¼, max=ä¸Šé™ã€‚")
    with col_kpi2:
        auto_fill = st.checkbox("ãƒ‰ãƒ¡ã‚¤ãƒ³ã«å¿œã˜ã¦è‡ªå‹•å…¥åŠ›", value=True, key="kpi_auto_fill")

    if st.button("KPIå€™è£œã‚’ææ¡ˆ", key="btn_kpi_templates"):
        base_query = ctx["complex"].get("refined") or {}
        refined_problem = base_query.get("refined_problem") if isinstance(base_query, dict) else {}
        user_query_text = (
            (refined_problem or {}).get("title")
            or ctx["complex"].get("user_query")
            or user_seed
        )
        if not user_query_text:
            st.warning("èª²é¡Œã‚’å…¥åŠ›ã—ã¦ã‹ã‚‰KPIã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("KPIãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™â€¦"):
                if _HAS_OPENAI and OPENAI_API_KEY:
                    agent = KPITemplateAgent()
                    resp = agent.run(
                        user_query=user_query_text,
                        domain_hint=kpi_domain_hint or ctx.get("domain"),
                        catalog_examples=KPI_CATALOG.get(kpi_domain_hint, []) if auto_fill else [],
                    )
                    templates = resp.get("kpi_candidates", [])
                else:
                    templates = [dict(item) for item in DEFAULT_KPI_TEMPLATES]
            ctx["complex"]["kpi_templates"] = templates
            ctx["complex"]["kpi_constraints"] = templates
            ctx["kpi_constraints"] = templates
            ctx["kpi_catalog"] = templates
            if templates:
                first_name = templates[0].get("name")
                set_kpi_targets(ctx, [first_name] if first_name else [])
                ctx["thr"] = templates[0].get("threshold_hint")
                ctx["kpi_threshold_type"] = templates[0].get("threshold_type", "min")
            st.success("KPIå€™è£œã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚ä¸‹è¡¨ã§é–¾å€¤ã‚„å®šç¾©ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")

    current_constraints = ctx["complex"].get("kpi_constraints") or ctx.get("kpi_constraints") or []
    if current_constraints:
        df_constraints = pd.DataFrame(current_constraints)
        column_config = {
            "name": st.column_config.TextColumn("KPIå", required=True),
            "definition": st.column_config.TextColumn("å®šç¾©"),
            "unit": st.column_config.TextColumn("å˜ä½"),
            "direction": st.column_config.SelectboxColumn("æŒ‡æ¨™æ–¹å‘", options=["up", "down"], help="up=å€¤ãŒå¤§ãã„ã»ã©è‰¯ã„"),
            "threshold_type": st.column_config.SelectboxColumn("é–¾å€¤ç¨®åˆ¥", options=["min", "max"], help="min=ä¸‹é™ã‚’å®ˆã‚‹, max=ä¸Šé™ã‚’è¶…ãˆãªã„"),
            "threshold_hint": st.column_config.NumberColumn("é–¾å€¤", format="%.2f"),
            "data_source": st.column_config.TextColumn("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹"),
            "legal_floor": st.column_config.TextColumn("æ³•ä»¤ãƒ»åŸºæº–"),
            "rationale": st.column_config.TextColumn("æ ¹æ‹ /å‡ºå…¸")
        }
        edited_df = st.data_editor(
            df_constraints,
            num_rows="dynamic",
            use_container_width=True,
            column_config=column_config,
            key="kpi_constraints_editor"
        )
        primary_options = [str(r.get("name", "")) for _, r in edited_df.iterrows() if str(r.get("name", ""))]
        default_targets = [t for t in get_kpi_targets(ctx) if t in primary_options]
        if not default_targets and primary_options:
            default_targets = [primary_options[0]]
        selected_targets = st.multiselect(
            "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¯¾è±¡ã®ä¸»è¦KPIï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
            primary_options,
            default=default_targets,
            key="primary_kpi_select"
        )
        if st.button("KPIè¨­å®šã‚’ä¿å­˜", key="btn_save_kpi_constraints"):
            records = edited_df.fillna("").to_dict("records")
            ctx["complex"]["kpi_constraints"] = records
            ctx["kpi_constraints"] = records
            ctx["complex"]["kpi_templates"] = ctx["complex"].get("kpi_templates") or records
            if records:
                targets_to_set = selected_targets or [records[0].get("name")]
            else:
                targets_to_set = selected_targets
            set_kpi_targets(ctx, targets_to_set or [])
            primary_name = get_primary_kpi_name(ctx)
            primary_constraint = next((r for r in records if r.get("name") == primary_name), records[0] if records else None)
            if primary_constraint:
                try:
                    ctx["thr"] = float(primary_constraint.get("threshold_hint"))
                except (TypeError, ValueError):
                    ctx["thr"] = None
                ctx["kpi_threshold_type"] = primary_constraint.get("threshold_type", "min")
            st.success("KPIåˆ¶ç´„ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
        with st.expander("KPIã‚³ãƒ¡ãƒ³ãƒˆ/åˆæ„çŠ¶æ³", expanded=False):
            kpi_comment = st.text_area("ã‚³ãƒ¡ãƒ³ãƒˆ", value=ctx["complex"].get("stage_notes", {}).get("KPI_COMMENT", ""), key="kpi_comment_box")
            if st.button("ã‚³ãƒ¡ãƒ³ãƒˆä¿å­˜", key="btn_save_kpi_comment"):
                ctx["complex"].setdefault("stage_notes", {})["KPI_COMMENT"] = kpi_comment
                st.success("KPIã‚³ãƒ¡ãƒ³ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    else:
        st.info("KPIå€™è£œãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ã€KPIå€™è£œã‚’ææ¡ˆã€ã‚’æŠ¼ã™ã‹ã€æ‰‹å‹•ã§è¡¨ã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")

    # --- Step 2: è³ªçš„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä»®èª¬ã‚’æŠ½å‡º ---
    st.markdown("---")
    st.subheader("2) è³ªçš„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŸå› ä»®èª¬ã‚’ç”Ÿæˆãƒ»æ•´ç†")
    st.caption("ãƒ’ã‚¢ãƒªãƒ³ã‚°ãƒ»è­°äº‹éŒ²ãƒ»SNSãªã©ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æã—ã€KJæ³•çš„ã«ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°")
    qual_files = st.file_uploader("è³ªçš„ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆtxt/csv, è¤‡æ•°å¯ï¼‰", type=["txt","csv","md"], accept_multiple_files=True, key="qual_files")

    if st.button("è³ªçš„ãƒ‡ãƒ¼ã‚¿ã‚’è§£æ", key="btn_analyze_qual"):
        entries = load_qualitative_entries(qual_files)
        used_sample = False
        if not entries:
            entries = [dict(sample) for sample in QUAL_SAMPLE_TEXTS]
            used_sample = True
        if not entries:
            st.warning("è³ªçš„ãƒ‡ãƒ¼ã‚¿ã‚’1ä»¶ä»¥ä¸ŠæŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        else:
            rows = analyze_qualitative(entries)
            pivot, gaps = summarize_hypotheses(rows)
            ctx["complex"]["qual_entries"] = entries
            ctx["complex"]["hypothesis_clusters"] = rows
            ctx["complex"]["evidence_gaps"] = [g["issue"] if isinstance(g, dict) else str(g) for g in gaps]
            ctx["complex"]["contention_points"] = find_contention_points(rows)
            st.success(f"{len(rows)}ä»¶ã®æ–­ç‰‡ã‹ã‚‰ä»®èª¬ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ã‚’ç·¨é›†ã—ã¦ãã ã•ã„ã€‚")
            if used_sample:
                st.info("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒãªã‹ã£ãŸãŸã‚ã€å…¬è¡¨è³‡æ–™ã‚¿ã‚¤ãƒˆãƒ«é¢¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§è§£æã—ã¾ã—ãŸã€‚")
            if not pivot.empty:
                st.dataframe(pivot, use_container_width=True)

    hypothesis_rows = ctx["complex"].get("hypothesis_clusters", [])
    if hypothesis_rows:
        df_hyp = pd.DataFrame(hypothesis_rows)
        edited_hyp = st.data_editor(
            df_hyp,
            num_rows="dynamic",
            use_container_width=True,
            column_config={
                "quote_id": st.column_config.TextColumn("ID", disabled=True),
                "source": st.column_config.TextColumn("ã‚½ãƒ¼ã‚¹"),
                "quote": st.column_config.TextColumn("å¼•ç”¨"),
                "cause": st.column_config.TextColumn("è‡ªå‹•æ¨å®šåŸå› ", disabled=True),
                "cluster_lv1": st.column_config.TextColumn("ä¸­é …ç›®"),
                "cluster_lv2": st.column_config.TextColumn("å°é …ç›®"),
                "importance": st.column_config.NumberColumn("é‡è¦åº¦", format="%d"),
                "evidence_link": st.column_config.TextColumn("ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒªãƒ³ã‚¯")
            },
            key="kj_editor"
        )
        if st.button("ä»®èª¬ã‚¯ãƒ©ã‚¹ã‚¿ã‚’ä¿å­˜", key="btn_save_hypothesis"):
            records = edited_hyp.to_dict("records")
            ctx["complex"]["hypothesis_clusters"] = records
            ctx["complex"]["contention_points"] = find_contention_points(records)
            ctx["complex"]["evidence_gaps"] = find_evidence_gaps(records)
            st.success("ä»®èª¬ã‚¯ãƒ©ã‚¹ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
        if st.button("ä»®èª¬ã®è£œå¼·ãƒ‡ãƒ¼ã‚¿ã‚’ææ¡ˆ", key="btn_gap_agent"):
            rows = ctx["complex"].get("hypothesis_clusters") or edited_hyp.to_dict("records")
            if not rows:
                st.warning("ä»®èª¬ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                try:
                    if _HAS_OPENAI and OPENAI_API_KEY:
                        gap_agent = HypothesisGapAgent()
                        resp = gap_agent.run(rows)
                    else:
                        raise RuntimeError("no-openai")
                except Exception:
                    resp = {"gap_analysis": fallback_gap_analysis(rows)}
                ctx["complex"]["hypothesis_gap_analysis"] = resp.get("gap_analysis", [])
                st.success("ä»®èª¬ã®è£œå¼·ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†ã—ã¾ã—ãŸã€‚")
        st.markdown("**å¯¾ç«‹ç‚¹ / é‡è¦è«–ç‚¹**")
        for item in ctx["complex"].get("contention_points", []):
            st.info(item)
        if ctx["complex"].get("evidence_gaps"):
            with st.expander("ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸è¶³ã®æŒ‡æ‘˜"):
                for gap in ctx["complex"]["evidence_gaps"]:
                    st.warning(gap)
        if ctx["complex"].get("hypothesis_gap_analysis"):
            st.markdown("**è£œå¼·ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ææ¡ˆ**")
            for entry in ctx["complex"]["hypothesis_gap_analysis"]:
                hypothesis = entry.get("hypothesis", "ä»®èª¬")
                concern = entry.get("concern", "")
                needed = ", ".join(entry.get("needed_data", []))
                priority = entry.get("priority", "medium")
                st.warning(f"[{priority}] {hypothesis}: {concern} â†’ æ¨å¥¨ãƒ‡ãƒ¼ã‚¿: {needed}")
        with st.expander("ä»®èª¬ã«é–¢ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆ", expanded=False):
            hyp_comment = st.text_area("åˆæ„çŠ¶æ³/æ‡¸å¿µ", value=ctx["complex"].get("stage_notes", {}).get("HYP_COMMENT", ""), key="hyp_comment_box")
            if st.button("ä»®èª¬ã‚³ãƒ¡ãƒ³ãƒˆã‚’ä¿å­˜", key="btn_save_hyp_comment"):
                ctx["complex"].setdefault("stage_notes", {})["HYP_COMMENT"] = hyp_comment
                st.success("ä»®èª¬ã‚³ãƒ¡ãƒ³ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    else:
        st.info("è³ªçš„ãƒ‡ãƒ¼ã‚¿ã®è§£æçµæœãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")

    # --- Step 3: æ–½ç­–ã‚ªãƒ—ã‚·ãƒ§ãƒ³åˆ—æŒ™ãƒ»æ¯”è¼ƒ ---
    st.markdown("---")
    st.subheader("3) åŸå› åˆ¥ã®æ–½ç­–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’åˆ—æŒ™ãƒ»æ¯”è¼ƒ")
    if st.button("åŸå› ä»®èª¬ã‹ã‚‰æ–½ç­–æ¡ˆã‚’ç”Ÿæˆ", key="btn_generate_policies"):
        options = generate_policy_options_from_hypotheses(ctx["complex"].get("hypothesis_clusters") or [])
        if not options:
            options = [
                {"æ–½ç­–": n, "åŸå› ã‚«ãƒ†ã‚´ãƒª": "å‚è€ƒ", "ã‚³ã‚¹ãƒˆ(å„„å††)": info["cost"], "åŠ¹æœ(ä¸­ä½)": info["effect"],
                 "åŠ¹æœ(æ‚²è¦³)": round(info["effect"]*0.7,1), "åŠ¹æœ(æ¥½è¦³)": round(info["effect"]*1.2,1),
                 "ãƒ©ã‚°(å¹´)": info["lag"], "ã‚¹ã‚¿ãƒƒãƒ•éœ€è¦": 5, "KPIç´ä»˜ã‘": get_primary_kpi_name(ctx),
                 "ãƒªã‚¹ã‚¯": info["risk"], "æ ¹æ‹ ": "ãƒ©ã‚¤ãƒ–ãƒ©ãƒª"}
                for n, info in POLICY_LIBRARY.items()
            ]
        ctx["complex"]["policy_options"] = options
        st.success(f"{len(options)}ä»¶ã®æ–½ç­–æ¡ˆã‚’å–å¾—ã—ã¾ã—ãŸã€‚")

    policy_options = ctx["complex"].get("policy_options") or []
    if policy_options:
        df_options = pd.DataFrame(policy_options)
        edited_options = st.data_editor(
            df_options,
            num_rows="dynamic",
            use_container_width=True,
            key="policy_options_editor"
        )
        ctx["complex"]["policy_options"] = edited_options.to_dict("records")
        st.plotly_chart(bubble_chart(edited_options.rename(columns={"åŠ¹æœ(ä¸­ä½)": "åŠ¹æœ(ä¸­ä½)", "ã‚³ã‚¹ãƒˆ(å„„å††)": "ã‚³ã‚¹ãƒˆ(å„„å††)"})), use_container_width=True)
        st.caption("å‰æ: åŠ¹æœ=KPIæ”¹å–„ã‚¹ã‚³ã‚¢ã€ã‚³ã‚¹ãƒˆ=å¹´é–“äºˆç®—ã€‚ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿ã§å„å€¤ã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚")
        selected_names = st.multiselect("æ¯”è¼ƒã™ã‚‹æ–½ç­–", edited_options["æ–½ç­–"].tolist(), default=edited_options["æ–½ç­–"].tolist()[:2], key="policy_select")
        if selected_names:
            subset = edited_options[edited_options["æ–½ç­–"].isin(selected_names)]
            st.dataframe(subset, use_container_width=True)
            cost_sum = subset["ã‚³ã‚¹ãƒˆ(å„„å††)"].sum()
            eff_sum = subset["åŠ¹æœ(ä¸­ä½)"].sum()
            st.info(f"é¸æŠæ–½ç­–ã®åˆè¨ˆ: ã‚³ã‚¹ãƒˆ {cost_sum:.1f} å„„å†† / æƒ³å®šåŠ¹æœ {eff_sum:.1f}")
        with st.expander("æ–½ç­–æ¯”è¼ƒãƒ¡ãƒ¢", expanded=False):
            plan_comment = st.text_area("ãƒ¡ãƒ¢", value=ctx["complex"].get("stage_notes", {}).get("PLAN_COMMENT", ""), key="plan_comment_box")
            if st.button("æ–½ç­–ãƒ¡ãƒ¢ã‚’ä¿å­˜", key="btn_save_plan_comment"):
                ctx["complex"].setdefault("stage_notes", {})["PLAN_COMMENT"] = plan_comment
                st.success("æ–½ç­–ãƒ¡ãƒ¢ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    else:
        st.info("æ–½ç­–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯ã¾ã ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    st.markdown("---")
    st.subheader("Agentã‚³ãƒ³ãƒš: è¤‡æ•°ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ã®ææ¡ˆã‚’æ¯”è¼ƒ")
    comp_ctx = ctx["complex"].get("agent_competition") or {}
    if st.button("ã‚³ãƒ³ãƒšã‚’å®Ÿè¡Œ", key="btn_agent_competition"):
        if not (ctx["complex"].get("refined") and ctx["complex"].get("workplan") and ctx["complex"].get("search_results")):
            st.warning("è©³ç´°åŒ–ãƒ»åˆ†è§£ãƒ»æ¤œç´¢ã‚’å®Œäº†ã•ã›ã¦ãã ã•ã„ã€‚")
        else:
            manager = AgentCompetitionManager()
            refined_payload = ctx["complex"].get("refined") or {}
            work_payload = ctx["complex"].get("workplan") or {}
            search_payload = ctx["complex"].get("search_results") or {}
            kpi_cands = refined_payload.get("refined_problem", {}).get("kpi_candidates", [])
            comp_ctx = manager.run(refined_payload, work_payload, search_payload, kpi_cands, DEFAULT_CONTESTANTS)
            ctx["complex"]["agent_competition"] = comp_ctx
            st.success("ã‚³ãƒ³ãƒšçµæœã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
    if comp_ctx.get("entries"):
        for entry in comp_ctx["entries"]:
            st.markdown(f"**{entry['contestant']} ({entry['theme']})**")
            st.json(entry["strategy"], expanded=False)
        if comp_ctx.get("critique"):
            st.markdown("**Critique Agent ã‚³ãƒ¡ãƒ³ãƒˆ**")
            st.json(comp_ctx["critique"], expanded=False)
    else:
        st.info("ã¾ã ã‚³ãƒ³ãƒšçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    # --- Step 4 & 5: åˆ†è§£â†’æ¤œç´¢â†’è¤‡æ•°æ¡ˆåˆæˆï¼ˆæ—¢å­˜ï¼‰ ---
    st.markdown("---")
    st.subheader("4) ä½œæ¥­åˆ†è§£â†’æ¤œç´¢â†’è§£æ±ºæ¡ˆ (å˜ä¸€)")
    st.caption("5) ãƒ†ãƒ¼ãƒã‚’å¤‰ãˆã¤ã¤ã€ä¸Šè¨˜ã‚’ç¹°ã‚Šè¿”ã—ã¦è¤‡æ•°æ¡ˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
    colA, colB, colC = st.columns(3)
    with colA:
        if st.button("åˆ†è§£ã‚’ç”Ÿæˆ"):
            if not ctx["complex"]["refined"] or not ctx["complex"]["confirmed"]:
                st.warning("ã¾ãšè©³ç´°åŒ–ã—ã€yã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                with st.spinner("åˆ†è§£ä¸­â€¦"):
                    ctx["complex"]["workplan"] = decompose_work(ctx["complex"]["refined"].get("refined_problem", ctx["complex"]["refined"]))
                with st.spinner("è«–ç‚¹æ´—ã„å‡ºã—ä¸­â€¦"):
                    ctx["complex"]["topic_map"] = explore_topics(
                        ctx["complex"].get("user_query") or "",
                        ctx["complex"].get("refined") or {},
                        ctx["complex"]["workplan"],
                    )
                st.success("åˆ†è§£ã¨è«–ç‚¹ãƒãƒƒãƒ—ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    with colB:
        if st.button("åˆ†è§£ã«åŸºã¥ãæ¤œç´¢ã‚’å®Ÿè¡Œ"):
            if not ctx["complex"]["workplan"]:
                st.warning("å…ˆã«ã€åˆ†è§£ã‚’ç”Ÿæˆã€ã—ã¦ãã ã•ã„ã€‚")
            else:
                with st.spinner("æ¤œç´¢ä¸­â€¦"):
                    ctx["complex"]["search_results"] = run_searches(
                        ctx["complex"]["workplan"],
                        prefer_rs_system=st.session_state.restrict_rs,
                        user_query=ctx["complex"].get("user_query"),
                        refined_problem=ctx["complex"].get("refined"),
                        topic_map=ctx["complex"].get("topic_map"),
                    )
                    ctx["complex"]["topic_layer_hits"] = ctx["complex"]["search_results"].get("topic_layer_hits")
                    ctx["complex"]["policy_hypotheses"] = build_policy_hypotheses(
                        ctx["complex"].get("user_query") or "",
                        ctx["complex"]["topic_layer_hits"] or {},
                    )
                st.success("æ¤œç´¢å®Œäº†")
    with colC:
        if st.button("è¤‡æ•°æ¡ˆã‚’ç”Ÿæˆï¼ˆãƒ†ãƒ¼ãƒ: è²»ç”¨å¯¾åŠ¹æœ/å…¬å¹³æ€§/ã‚¹ãƒ”ãƒ¼ãƒ‰ï¼‰"):
            if not (ctx["complex"]["refined"] and ctx["complex"]["workplan"] and ctx["complex"]["search_results"]):
                st.warning("è©³ç´°åŒ–â†’åˆ†è§£â†’æ¤œç´¢ã‚’æ¸ˆã¾ã›ã¦ãã ã•ã„ã€‚")
            else:
                with st.spinner("æ”¿ç­–æ¡ˆåˆæˆä¸­â€¦"):
                    n_alts_val = int(st.session_state.get("n_alts", 3))
                    ctx["complex"]["strategies"] = synthesize_strategies(
                        ctx["complex"]["refined"], ctx["complex"]["workplan"], ctx["complex"]["search_results"], n_alternatives=n_alts_val
                    )
                st.success(f"æ”¿ç­–æ¡ˆã‚’ {len(ctx['complex']['strategies'])} ä»¶ç”Ÿæˆã—ã¾ã—ãŸã€‚")

    if ctx["complex"]["workplan"]:
        st.markdown("**åˆ†è§£çµæœ**")
        st.json(ctx["complex"]["workplan"])
    if ctx["complex"].get("topic_map"):
        st.markdown("**è«–ç‚¹ãƒãƒƒãƒ—ï¼ˆéšå±¤è¡¨ç¤ºï¼‰**")
        render_topic_map(ctx["complex"]["topic_map"])
    if ctx["complex"].get("policy_hypotheses"):
        st.markdown("**éšå±¤åˆ¥ æ”¿ç­–ä»®èª¬**")
        render_policy_hypotheses(ctx["complex"]["policy_hypotheses"])

    # --- Step 5: ã‚·ãƒŠãƒªã‚ªã¨è³‡æºé…åˆ†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ---
    st.markdown("---")
    st.subheader("5) åˆ¶ç´„ä¸‹ã§ã®è³‡æºé…åˆ†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    scenario_records = ctx["complex"].get("scenario_configs") or SCENARIO_TEMPLATES
    scenario_df = st.data_editor(
        pd.DataFrame(scenario_records),
        num_rows="dynamic",
        use_container_width=True,
        key="scenario_editor"
    )
    if st.button("ã‚·ãƒŠãƒªã‚ªè¨­å®šã‚’ä¿å­˜", key="btn_save_scenarios"):
        ctx["complex"]["scenario_configs"] = scenario_df.fillna(0).to_dict("records")
        st.success("ã‚·ãƒŠãƒªã‚ªè¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    scenario_names = scenario_df.get("name", pd.Series(dtype=str)).tolist()
    if scenario_names:
        scenario_choice = st.selectbox("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¯¾è±¡ã‚·ãƒŠãƒªã‚ª", scenario_names, key="scenario_choice")
        if st.button("ã“ã®ã‚·ãƒŠãƒªã‚ªã§æœ€é©åŒ–", key="btn_run_scenario"):
            options_df = pd.DataFrame(ctx["complex"].get("policy_options") or [])
            scenario_row = scenario_df[scenario_df["name"] == scenario_choice].iloc[0].to_dict()
            selected = optimize_scenario_allocation(
                options_df,
                scenario_row.get("budget", 0.0),
                scenario_row.get("staff_limit", 0.0),
            )
            ctx["complex"]["picked"] = selected
            years = ctx["years"]
            result = simulate_scenario(years, scenario_row, selected)
            ctx["complex"].setdefault("scenario_results", {})[scenario_choice] = result
            st.success(f"{scenario_choice} ã®æœ€é©åŒ–ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚")
            st.dataframe(selected, use_container_width=True)
            st.caption(f"å‰æ: ã‚·ãƒŠãƒªã‚ª {scenario_choice} ã®é¢„ç®—={scenario_row.get('budget')}å„„å†† / äººå“¡={scenario_row.get('staff_limit')}äººã€‚")
            targets = get_kpi_targets(ctx) or [ctx.get("kpi") or "KPI"]
            constraints = ctx.get("kpi_constraints", []) or []
            for target in targets:
                constraint = next((c for c in constraints if c.get("name") == target), None)
                thr_value = _to_float((constraint or {}).get("threshold_hint"))
                threshold_lines = None
                if thr_value is not None and constraint:
                    unit = constraint.get("unit") or ""
                    label_text = f"{target or 'KPI'} â‰§ {thr_value}{unit}" if (constraint.get("threshold_type") or "min") == "min" else f"{target or 'KPI'} â‰¦ {thr_value}{unit}"
                    threshold_lines = [{"value": thr_value, "label": label_text}]
                st.markdown(f"**{target or 'KPI'} ã®ãƒ¬ãƒ³ã‚¸**")
                st.plotly_chart(
                    band_chart(years, result["mid"], result["low"], result["high"], None, target or 'KPI', threshold_lines),
                    use_container_width=True,
                    key=f"scenario_band_{scenario_choice}_{target}"
                )
                alerts = threshold_breaches(years, result["low"], result["high"], constraint) if constraint else []
                for al in alerts:
                    st.error(al)

    # --- Step 6: ãƒªã‚¹ã‚¯ã¨ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹é€æ˜æ€§ ---
    st.markdown("---")
    st.subheader("6) åŠ¹æœãƒ»ãƒªã‚¹ã‚¯ã®å¯è¦–åŒ–ã¨é€æ˜æ€§")
    risk_df = st.data_editor(
        pd.DataFrame(ctx["complex"].get("risk_register") or RISK_SAMPLE),
        num_rows="dynamic",
        use_container_width=True,
        key="risk_editor"
    )
    ctx["complex"]["risk_register"] = risk_df.to_dict("records")
    exposure = calc_risk_exposure(ctx["complex"].get("risk_register"), ctx.get("picked"))
    if not exposure.empty:
        st.markdown("**ãƒªã‚¹ã‚¯æ„Ÿåº¦åˆ†æ**")
        st.dataframe(exposure, use_container_width=True)
        st.bar_chart(exposure.set_index("risk")["expected_impact"], use_container_width=True)
    else:
        st.info("ãƒªã‚¹ã‚¯ç™»éŒ²ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.markdown("**å¯¾ç«‹ç‚¹ / æœªæ±ºè«–ç‚¹**")
    if ctx["complex"].get("contention_points"):
        for item in ctx["complex"]["contention_points"]:
            st.info(item)
    else:
        st.write("ç¾åœ¨ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹å¯¾ç«‹ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.markdown("**ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä¸è¶³ç®‡æ‰€**")
    if ctx["complex"].get("evidence_gaps"):
        for gap in ctx["complex"]["evidence_gaps"]:
            st.warning(gap)
    else:
        st.write("ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚®ãƒ£ãƒƒãƒ—ã¯æ¤œå‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.markdown("**é–¢ä¿‚è€…å‘ã‘ãƒ†ãƒ³ãƒ—ãƒ¬**")
    templates = st.session_state.context.get("stakeholder_templates", [])
    if templates:
        for tpl in reversed(templates[-3:]):
            st.code(tpl.get("template") if isinstance(tpl, dict) else str(tpl), language="markdown")
    else:
        st.write("ã¾ã ãƒ†ãƒ³ãƒ—ãƒ¬ã¯ä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒãƒ£ãƒƒãƒˆã§ã€é–¢ä¿‚è€…ã«ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€ç­‰ã¨å…¥åŠ›ã—ã¦ç”Ÿæˆã§ãã¾ã™ã€‚")
    st.markdown("**æ„æ€æ±ºå®šãƒ¡ãƒ¢**")
    decision_input = st.text_area("æœ€çµ‚åˆ¤æ–­ãƒ¡ãƒ¢", value=ctx["complex"].get("decision_notes", ""), key="decision_notes_box")
    if st.button("æ„æ€æ±ºå®šãƒ¡ãƒ¢ã‚’ä¿å­˜", key="btn_save_decision_notes"):
        ctx["complex"]["decision_notes"] = decision_input
        st.success("æ„æ€æ±ºå®šãƒ¡ãƒ¢ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    if ctx["complex"]["search_results"]:
        st.markdown("**æ¤œç´¢çµæœãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ**")
        pr = ctx["complex"]["search_results"].get("policy_hits", [])
        pa = ctx["complex"]["search_results"].get("paper_hits", [])
        st.write(f"æ”¿ç­–å€™è£œ: {len(pr)} ä»¶ / è«–æ–‡å€™è£œ: {len(pa)} ä»¶")
    if ctx["complex"]["strategies"]:
        st.markdown("**ç”Ÿæˆã•ã‚ŒãŸæ”¿ç­–æ¡ˆï¼ˆè¤‡æ•°ï¼‰**")
        for i, s in enumerate(ctx["complex"]["strategies"], start=1):
            with st.expander(f"[{i}] {s.get('name','strategy')}", expanded=(i==1)):
                st.write(f"ãƒ†ãƒ¼ãƒ: {s.get('theme')}")
                st.write(s.get("summary", s.get("rationale", "")))
                st.write("**æ¡ç”¨æ”¿ç­–å€™è£œ**")
                render_policy_actions(s.get("policies") or s.get("actions") or [])
                st.write("**ãƒ­ã‚¸ãƒƒã‚¯ãƒ„ãƒªãƒ¼ï¼ˆã‚°ãƒ©ãƒ•ï¼‰**")
                render_logic_tree_graph(s.get("logic_tree"))
                st.write("**ãƒ­ã‚¸ãƒƒã‚¯ãƒ„ãƒªãƒ¼ï¼ˆJSONï¼‰**")
                st.json(s.get("logic_tree", {}))
                meta = s.get("rlhf_meta")
                if meta:
                    st.caption(f"RLHFé¢¨ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè©•ä¾¡ã‚¹ã‚³ã‚¢: {meta.get('reward', 0)}")
                    if meta.get("critic_log"):
                        with st.expander("æ‰¹è©•ãƒ­ã‚°ï¼ˆææ¡ˆè€…Ã—æ‰¹è©•è€…ã®å¯¾è©±ï¼‰", expanded=False):
                            st.json(meta.get("critic_log"))

    # --- Step 4: æ‰¹åˆ¤çš„æ¤œè¨ ---
    st.markdown("---")
    st.subheader("4) æ‰¹åˆ¤çš„æ¤œè¨ï¼ˆä½•ãŒçŠ ç‰²ã«ãªã‚‹ã‹ï¼‰")
    if st.button("æ‰¹åˆ¤ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œ"):
        if not ctx["complex"]["strategies"]:
            st.warning("å…ˆã«è¤‡æ•°æ¡ˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­â€¦"):
                has_key = bool((OPENAI_API_KEY or "").strip())
                if _HAS_OPENAI and has_key:
                    remote = critique_strategies(ctx["complex"]["strategies"])
                else:
                    remote = {"reviews": [], "cross_cutting_observations": []}
                if not remote.get("reviews"):
                    remote = local_critique(ctx["complex"]["strategies"])
                ctx["complex"]["critique"] = remote
            st.success("ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº†")
    if ctx["complex"].get("critique"):
        st.json(ctx["complex"]["critique"])
    else:
        st.info("ã¾ã æ‰¹åˆ¤ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    # --- Step 5: äºˆç®—æ¨å®šã¨æ®µéšåˆ¥å¯è¦–åŒ– ---
    st.markdown("---")
    st.subheader("5) RSã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰éå»äºˆç®—ã‚’æ¢ç´¢ã—ã€æ®µéšåˆ¥ã«å¯è¦–åŒ–")
    if st.button("äºˆç®—æ¢ç´¢ã¨å¯è¦–åŒ–ï¼ˆæˆ¦ç•¥ã”ã¨ï¼‰"):
        if not ctx["complex"]["strategies"]:
            st.warning("å…ˆã«è¤‡æ•°æ¡ˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("äºˆç®—æ¢ç´¢ãƒ»é…åˆ†â€¦"):
                ctx["complex"]["budgets"] = estimate_budgets(ctx["complex"]["strategies"])
            st.success("äºˆç®—æ¨å®šå®Œäº†")

    st.markdown("**KPI Îµåˆ¶ç´„æœ€é©åŒ–**")
    effect_inputs = build_effect_inputs(st.session_state)
    if not HAS_PULP:
        st.warning("PuLP ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`pip install pulp` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    elif not effect_inputs:
        st.info("KPIåˆ¶ç´„ã¾ãŸã¯æ–½ç­–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚Step2/3ã§KPIã¨æ–½ç­–ã‚’ç™»éŒ²ã™ã‚‹ã¨æœ€é©åŒ–ã§ãã¾ã™ã€‚")
    else:
        effect, y_base, eps_default, budget_default, kpi_names, policy_names = effect_inputs
        st.caption("å„KPIã®æœ€ä½è¨±å®¹æ°´æº–(Îµ)ã¨ç·äºˆç®—ã‚’èª¿æ•´ã™ã‚‹ã¨ã€Îµåˆ¶ç´„æ³•ã§ã‚¿ãƒ¼ã‚²ãƒƒãƒˆKPIã‚’é †ç•ªã«æœ€å¤§åŒ–ã—ã¾ã™ã€‚")
        epsilon_df = pd.DataFrame({
            "KPI": kpi_names,
            "ç¾çŠ¶å€¤": np.round(y_base, 2),
            "Îµåˆ¶ç´„(ä¸‹é™)": np.round(eps_default, 2),
        })
        column_config = {
            "KPI": st.column_config.TextColumn("KPI", disabled=True),
            "ç¾çŠ¶å€¤": st.column_config.NumberColumn("ç¾çŠ¶å€¤", format="%.2f", disabled=True),
            "Îµåˆ¶ç´„(ä¸‹é™)": st.column_config.NumberColumn("Îµåˆ¶ç´„(ä¸‹é™)", format="%.2f"),
        }
        edited_eps = st.data_editor(
            epsilon_df,
            use_container_width=True,
            column_config=column_config,
            key="epsilon_editor"
        )
        eps_arr = edited_eps["Îµåˆ¶ç´„(ä¸‹é™)"].astype(float).to_numpy()
        budget_val = st.number_input(
            "ç·äºˆç®—åˆ¶ç´„ï¼ˆå„„å††ï¼‰",
            min_value=0.0,
            value=float(budget_default),
            step=0.5,
            key="epsilon_budget_input"
        )
        if st.button("Îµåˆ¶ç´„ã§KPIæœ€é©åŒ–", key="btn_epsilon_opt"):
            with st.spinner("Îµåˆ¶ç´„ã«åŸºã¥ãæœ€é©é…åˆ†ã‚’æ¢ç´¢ä¸­â€¦"):
                sols = epsilon_constraint_allocation(effect, y_base, budget_val, eps_arr)
                st.session_state.context["complex"].setdefault("epsilon_alloc", {})
                st.session_state.context["complex"]["epsilon_alloc"] = {
                    "solutions": sols,
                    "kpis": kpi_names,
                    "policies": policy_names,
                    "budget": budget_val,
                }
                st.success("Îµåˆ¶ç´„æœ€é©åŒ–ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚")
    eps_ctx = st.session_state.context.get("complex", {}).get("epsilon_alloc")
    if eps_ctx:
        kpi_names = eps_ctx.get("kpis", [])
        policy_names = eps_ctx.get("policies", [])
        sols = eps_ctx.get("solutions", {}) or {}
        targets = []
        for target, sol in sorted(sols.items()):
            target_name = kpi_names[target] if target < len(kpi_names) else f"KPI{target}"
            targets.append((target_name, sol))
        if targets:
            st.markdown("**æœ€é©åŒ–çµæœï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ¥ï¼‰**")
            tabs = st.tabs([name for name, _ in targets])
            for tab, (name, sol) in zip(tabs, targets):
                with tab:
                    st.caption(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆKPI: {name} ï½œ ç·äºˆç®— {eps_ctx.get('budget', 0):.2f} å„„å††")
                    df_alloc = pd.DataFrame({"æ–½ç­–": policy_names, "é…åˆ†(å„„å††)": sol.get("allocation", [])}).round(3)
                    st.dataframe(df_alloc, use_container_width=True)
                    df_pred = pd.DataFrame({"KPI": kpi_names, "äºˆæ¸¬å€¤": sol.get("KPI_pred", [])}).round(3)
                    if not df_pred.empty:
                        st.bar_chart(df_pred.set_index("KPI"), use_container_width=True)
                    st.dataframe(df_pred, use_container_width=True)

    # Sankey å¯è¦–åŒ–
    if ctx["complex"]["budgets"]:
        import plotly.graph_objects as go
        st.markdown("### äºˆç®—ã®æ®µéšåˆ¥Sankeyï¼ˆå„æˆ¦ç•¥ï¼‰")
        for i, (s, b) in enumerate(zip(ctx["complex"]["strategies"], ctx["complex"]["budgets"]), start=1):
            st.markdown(f"**[{i}] {s.get('name','strategy')}**")
            # ãƒãƒ¼ãƒ‰æ§‹æˆ: Input(äºˆç®—) â†’ Activities(å„æ”¿ç­–) â†’ Outputs/Outcomes(é›†ç´„)
            acts = s.get("logic_tree", {}).get("activities", [])
            alloc = b.get("allocation", {})
            per = alloc.get("per_activity_budget", [])
            prof = alloc.get("allocation_profile", {"activity":0.6,"output":0.25,"outcome_short":0.1,"outcome_mid":0.04,"outcome_long":0.01})
            # ãƒãƒ¼ãƒ‰
            labels = ["äºˆç®—"]
            idx = {"äºˆç®—": 0}
            # æ´»å‹•
            for a in acts:
                lab = a.get("label", a.get("id",""))
                idx[lab] = len(labels); labels.append(lab)
            # æ®µéšãƒãƒ¼ãƒ‰
            for L in ["Outputs","Outcomes(S)","Outcomes(M)","Outcomes(L)"]:
                idx[L] = len(labels); labels.append(L)

            # ãƒªãƒ³ã‚¯
            links = {"source": [], "target": [], "value": []}
            total_activity = 0.0
            # äºˆç®—â†’æ´»å‹•
            for a in per:
                lab = a.get("activity_label") or a.get("activity_id","")
                v = float(a.get("estimated_yen", 0.0))
                total_activity += v
                if lab in idx and v > 0:
                    links["source"].append(idx["äºˆç®—"]); links["target"].append(idx[lab]); links["value"].append(v)
            # æ´»å‹•â†’å‡ºåŠ›/ã‚¢ã‚¦ãƒˆã‚«ãƒ ï¼ˆé…åˆ†ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
            for a in per:
                lab = a.get("activity_label") or a.get("activity_id","")
                v = float(a.get("estimated_yen", 0.0))
                if lab not in idx or v <= 0: continue
                links["source"].append(idx[lab]); links["target"].append(idx["Outputs"]);      links["value"].append(v*float(prof.get("output",0.25)))
                links["source"].append(idx[lab]); links["target"].append(idx["Outcomes(S)"]); links["value"].append(v*float(prof.get("outcome_short",0.1)))
                links["source"].append(idx[lab]); links["target"].append(idx["Outcomes(M)"]); links["value"].append(v*float(prof.get("outcome_mid",0.04)))
                links["source"].append(idx[lab]); links["target"].append(idx["Outcomes(L)"]); links["value"].append(v*float(prof.get("outcome_long",0.01)))

            fig = go.Figure(data=[go.Sankey(
                node=dict(pad=10, thickness=16, line=dict(color="black", width=0.3), label=labels),
                link=links
            )])
            fig.update_layout(height=420, margin=dict(l=10,r=10,t=30,b=10), title=f"äºˆç®—æ¨å®šåˆè¨ˆ: {total_activity:,.0f} å††ï¼ˆé…åˆ†æ¯”ç‡ã«åŸºã¥ãæ®µéšåˆ¥ãƒ•ãƒ­ãƒ¼ï¼‰")
            st.plotly_chart(fig, use_container_width=True, key=f"sankey_{i}")

        st.markdown("**æŠ½å‡ºå…ƒãƒšãƒ¼ã‚¸ï¼ˆä¸Šä½ï¼‰**")
        for i, b in enumerate(ctx["complex"]["budgets"], start=1):
            st.markdown(f"- æˆ¦ç•¥[{i}] {b.get('strategy_name','')}")
            cands = b.get("candidates", [])[:8]
            for c in cands:
                st.write(f"  - {c['raw']} / {c['yen']:,.0f} å††  â€”  {c['source_title']}  ({c['source_url']})")
